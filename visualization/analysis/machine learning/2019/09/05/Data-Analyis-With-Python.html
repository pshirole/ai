<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Data Analysis using Python | Pranav Shirole</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Data Analysis using Python" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Data analysis of an automobile dataset using various techniques." />
<meta property="og:description" content="Data analysis of an automobile dataset using various techniques." />
<link rel="canonical" href="https://pshirole.github.io/ai/visualization/analysis/machine%20learning/2019/09/05/Data-Analyis-With-Python.html" />
<meta property="og:url" content="https://pshirole.github.io/ai/visualization/analysis/machine%20learning/2019/09/05/Data-Analyis-With-Python.html" />
<meta property="og:site_name" content="Pranav Shirole" />
<meta property="og:image" content="https://pshirole.github.io/ai/images/some_folder/your_image.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-09-05T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2019-09-05T00:00:00-05:00","url":"https://pshirole.github.io/ai/visualization/analysis/machine%20learning/2019/09/05/Data-Analyis-With-Python.html","@type":"BlogPosting","dateModified":"2019-09-05T00:00:00-05:00","image":"https://pshirole.github.io/ai/images/some_folder/your_image.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://pshirole.github.io/ai/visualization/analysis/machine%20learning/2019/09/05/Data-Analyis-With-Python.html"},"headline":"Data Analysis using Python","description":"Data analysis of an automobile dataset using various techniques.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ai/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://pshirole.github.io/ai/feed.xml" title="Pranav Shirole" /><link rel="shortcut icon" type="image/x-icon" href="/ai/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/ai/">Pranav Shirole</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/ai/about/">About Me</a><a class="page-link" href="/ai/search/">Search</a><a class="page-link" href="/ai/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Data Analysis using Python</h1><p class="page-description">Data analysis of an automobile dataset using various techniques.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2019-09-05T00:00:00-05:00" itemprop="datePublished">
        Sep 5, 2019
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      66 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/ai/categories/#visualization">visualization</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ai/categories/#analysis">analysis</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ai/categories/#machine learning">machine learning</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h4"><a href="#attribute-information">Attribute Information:</a></li>
<li class="toc-entry toc-h2"><a href="#data-acquisition">Data Acquisition</a></li>
<li class="toc-entry toc-h2"><a href="#data-wrangling">Data Wrangling</a>
<ul>
<li class="toc-entry toc-h5"><a href="#replace-by-mean">Replace by mean</a></li>
<li class="toc-entry toc-h5"><a href="#replace-by-frequency">Replace by Frequency</a></li>
<li class="toc-entry toc-h5"><a href="#drop-the-whole-row">Drop the whole row</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#data-normalization">Data Normalization</a>
<ul>
<li class="toc-entry toc-h3"><a href="#binning">Binning</a>
<ul>
<li class="toc-entry toc-h4"><a href="#bins-visualization">Bins Visualization</a></li>
<li class="toc-entry toc-h4"><a href="#indicator-variable-or-dummy-variable">Indicator variable (or dummy variable)</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#analyzing-individual-feature-patterns-using-visualization">Analyzing Individual Feature Patterns using Visualization</a>
<ul>
<li class="toc-entry toc-h4"><a href="#continuous-numerical-variables">Continuous numerical variables</a></li>
<li class="toc-entry toc-h4"><a href="#correlation">Correlation</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#continuos-numerical-variables">Continuos numerical variables</a>
<ul>
<li class="toc-entry toc-h5"><a href="#positive-linear-relationship">Positive Linear Relationship</a></li>
<li class="toc-entry toc-h5"><a href="#weak-linear-relationship">Weak Linear Relationship</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#categorical-variables">Categorical variables</a></li>
<li class="toc-entry toc-h3"><a href="#descriptive-statistical-analysis">Descriptive Statistical Analysis</a></li>
<li class="toc-entry toc-h3"><a href="#grouping">Grouping</a></li>
<li class="toc-entry toc-h3"><a href="#correlation-and-causation">Correlation and Causation</a></li>
<li class="toc-entry toc-h3"><a href="#anova-analyis-of-variance">ANOVA (Analyis of Variance)</a>
<ul>
<li class="toc-entry toc-h4"><a href="#conclusion-important-variables">Conclusion: Important Variables</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#model-development">Model Development</a>
<ul>
<li class="toc-entry toc-h3"><a href="#linear-regression-and-multiple-linear-regression">Linear Regression and Multiple Linear Regression</a></li>
<li class="toc-entry toc-h3"><a href="#simple-linear-regression">Simple Linear Regression</a>
<ul>
<li class="toc-entry toc-h6"><a href="#how-can-highway-mpg-help-predict-the-price">How can highway-mpg help predict the price?</a></li>
<li class="toc-entry toc-h6"><a href="#how-can-engine-size-help-predict-the-price">How can engine size help predict the price?</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#multiple-linear-regression">Multiple Linear Regression</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#model-evaluation-using-visualization">Model Evaluation using Visualization</a>
<ul>
<li class="toc-entry toc-h3"><a href="#regression-plot-for-simple-linear-regression">Regression Plot for Simple Linear Regression</a>
<ul>
<li class="toc-entry toc-h5"><a href="#residual-plot-to-visualize-variance-of-data">Residual Plot to visualize variance of data</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#distribution-plot-for-multiple-linear-regression">Distribution Plot for Multiple Linear Regression</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#polynomial-regression-and-pipelines">Polynomial Regression and Pipelines</a>
<ul>
<li class="toc-entry toc-h3"><a href="#multivariate-polynomial-function">Multivariate Polynomial Function</a></li>
<li class="toc-entry toc-h3"><a href="#pipeline">Pipeline</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#measures-for-in-sample-evaluation">Measures for In-Sample Evaluation</a>
<ul>
<li class="toc-entry toc-h3"><a href="#model-1-simple-linear-regression">Model 1: Simple Linear Regression</a></li>
<li class="toc-entry toc-h3"><a href="#model-2-multiple-linear-regression">Model 2: Multiple Linear Regression</a>
<ul>
<li class="toc-entry toc-h4"><a href="#model-3-polynomial-fit">Model 3: Polynomial Fit</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#prediction-and-decision-making">Prediction and Decision Making</a>
<ul>
<li class="toc-entry toc-h4"><a href="#prediction">Prediction</a></li>
<li class="toc-entry toc-h3"><a href="#decision-making-determing-a-good-model-fit">Decision Making: Determing a Good Model Fit</a>
<ul>
<li class="toc-entry toc-h4"><a href="#lets-take-a-look-at-the-values-for-the-different-models">Let’s take a look at the values for the different models.</a></li>
<li class="toc-entry toc-h4"><a href="#simple-linear-regression-model-slr-vs-multiple-linear-regression-model-mlr">Simple Linear Regression model (SLR) vs Multiple Linear Regression model (MLR)</a></li>
<li class="toc-entry toc-h4"><a href="#simple-linear-model-slr-vs-polynomial-fit">Simple Linear Model (SLR) vs Polynomial Fit</a></li>
<li class="toc-entry toc-h4"><a href="#multiple-linear-regression-mlr-vs-polynomial-fit">Multiple Linear Regression (MLR) vs Polynomial Fit</a></li>
<li class="toc-entry toc-h4"><a href="#conclusion">Conclusion:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#model-evaluation-and-refinement">Model Evaluation and Refinement</a>
<ul>
<li class="toc-entry toc-h4"><a href="#functions-for-plotting">Functions for Plotting</a></li>
<li class="toc-entry toc-h3"><a href="#training-and-testing">Training and Testing</a></li>
<li class="toc-entry toc-h3"><a href="#cross-validation-score">Cross-Validation Score</a></li>
<li class="toc-entry toc-h3"><a href="#overfitting-underfitting-and-model-selection">Overfitting, Underfitting and Model Selection</a></li>
<li class="toc-entry toc-h3"><a href="#overfitting">Overfitting</a></li>
<li class="toc-entry toc-h3"><a href="#ridge-regression">Ridge Regression</a></li>
<li class="toc-entry toc-h3"><a href="#grid-search">Grid Search</a></li>
</ul>
</li>
</ul><p>In this blog post, we will be conducting data analysis by various techniques using Python on an automobile dataset. The topics covered include data acquisition, wrangling, normalization, and visualization. We will also create a machine learning model and evaluate it.</p>

<p>We will be using a dataset about cars from back in 1985. This data set consists of three types of entities:</p>
<ul>
  <li>the specification of an auto in terms of various characteristics,</li>
  <li>its assigned insurance risk rating,</li>
  <li>its normalized losses in use as compared to other cars.</li>
</ul>

<p>The second entity corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process “symboling”. A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe. The third entity is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/specialty, etc…), and represents the average loss per car per year.</p>

<h4 id="attribute-information">
<a class="anchor" href="#attribute-information" aria-hidden="true"><span class="octicon octicon-link"></span></a>Attribute Information:</h4>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>symboling: -3, -2, -1, 0, 1, 2, 3
normalized-losses: continuous from 65 to 256
make: alfa-romero, audi, bmw, chevrolet, dodge, honda, isuzu, jaguar, mazda, mercedes-benz, mercury, mitsubishi, nissan, peugot, plymouth, porsche, renault, saab, subaru, toyota, volkswagen, volvo
fuel-type: diesel, gas
aspiration: std, turbo
num-of-doors: four, two
body-style: hardtop, wagon, sedan, hatchback, convertible
drive-wheels: 4wd, fwd, rwd
engine-location: front, rear
wheel-base: continuous from 86.6 120.9
length: continuous from 141.1 to 208.1
width: continuous from 60.3 to 72.3
height: continuous from 47.8 to 59.8
curb-weight: continuous from 1488 to 4066
engine-type: dohc, dohcv, l, ohc, ohcf, ohcv, rotor
num-of-cylinders: eight, five, four, six, three, twelve, two
engine-size: continuous from 61 to 326
fuel-system: 1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi
bore: continuous from 2.54 to 3.94
stroke: continuous from 2.07 to 4.17
compression-ratio: continuous from 7 to 23
horsepower: continuous from 48 to 288
peak-rpm: continuous from 4150 to 6600
city-mpg: continuous from 13 to 49
highway-mpg: continuous from 16 to 54
price: continuous from 5118 to 45400.
</code></pre></div></div>

<h2 id="data-acquisition">
<a class="anchor" href="#data-acquisition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Acquisition</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># read the online file and assign it to the variable 'df'
</span><span class="n">path</span> <span class="o">=</span> <span class="s">'imports-85.data'</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="c1"># print the first 10 rows of the dataset
</span><span class="k">print</span><span class="p">(</span><span class="s">'The first 10 rows of the dataframe'</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The first 10 rows of the dataframe
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>16</th>
      <th>17</th>
      <th>18</th>
      <th>19</th>
      <th>20</th>
      <th>21</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
      <th>25</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>?</td>
      <td>alfa-romero</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>convertible</td>
      <td>rwd</td>
      <td>front</td>
      <td>88.6</td>
      <td>...</td>
      <td>130</td>
      <td>mpfi</td>
      <td>3.47</td>
      <td>2.68</td>
      <td>9.0</td>
      <td>111</td>
      <td>5000</td>
      <td>21</td>
      <td>27</td>
      <td>13495</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>?</td>
      <td>alfa-romero</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>convertible</td>
      <td>rwd</td>
      <td>front</td>
      <td>88.6</td>
      <td>...</td>
      <td>130</td>
      <td>mpfi</td>
      <td>3.47</td>
      <td>2.68</td>
      <td>9.0</td>
      <td>111</td>
      <td>5000</td>
      <td>21</td>
      <td>27</td>
      <td>16500</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>?</td>
      <td>alfa-romero</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>hatchback</td>
      <td>rwd</td>
      <td>front</td>
      <td>94.5</td>
      <td>...</td>
      <td>152</td>
      <td>mpfi</td>
      <td>2.68</td>
      <td>3.47</td>
      <td>9.0</td>
      <td>154</td>
      <td>5000</td>
      <td>19</td>
      <td>26</td>
      <td>16500</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>164</td>
      <td>audi</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>99.8</td>
      <td>...</td>
      <td>109</td>
      <td>mpfi</td>
      <td>3.19</td>
      <td>3.40</td>
      <td>10.0</td>
      <td>102</td>
      <td>5500</td>
      <td>24</td>
      <td>30</td>
      <td>13950</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>164</td>
      <td>audi</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>4wd</td>
      <td>front</td>
      <td>99.4</td>
      <td>...</td>
      <td>136</td>
      <td>mpfi</td>
      <td>3.19</td>
      <td>3.40</td>
      <td>8.0</td>
      <td>115</td>
      <td>5500</td>
      <td>18</td>
      <td>22</td>
      <td>17450</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2</td>
      <td>?</td>
      <td>audi</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>99.8</td>
      <td>...</td>
      <td>136</td>
      <td>mpfi</td>
      <td>3.19</td>
      <td>3.40</td>
      <td>8.5</td>
      <td>110</td>
      <td>5500</td>
      <td>19</td>
      <td>25</td>
      <td>15250</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>158</td>
      <td>audi</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>105.8</td>
      <td>...</td>
      <td>136</td>
      <td>mpfi</td>
      <td>3.19</td>
      <td>3.40</td>
      <td>8.5</td>
      <td>110</td>
      <td>5500</td>
      <td>19</td>
      <td>25</td>
      <td>17710</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1</td>
      <td>?</td>
      <td>audi</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>wagon</td>
      <td>fwd</td>
      <td>front</td>
      <td>105.8</td>
      <td>...</td>
      <td>136</td>
      <td>mpfi</td>
      <td>3.19</td>
      <td>3.40</td>
      <td>8.5</td>
      <td>110</td>
      <td>5500</td>
      <td>19</td>
      <td>25</td>
      <td>18920</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1</td>
      <td>158</td>
      <td>audi</td>
      <td>gas</td>
      <td>turbo</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>105.8</td>
      <td>...</td>
      <td>131</td>
      <td>mpfi</td>
      <td>3.13</td>
      <td>3.40</td>
      <td>8.3</td>
      <td>140</td>
      <td>5500</td>
      <td>17</td>
      <td>20</td>
      <td>23875</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0</td>
      <td>?</td>
      <td>audi</td>
      <td>gas</td>
      <td>turbo</td>
      <td>two</td>
      <td>hatchback</td>
      <td>4wd</td>
      <td>front</td>
      <td>99.5</td>
      <td>...</td>
      <td>131</td>
      <td>mpfi</td>
      <td>3.13</td>
      <td>3.40</td>
      <td>7.0</td>
      <td>160</td>
      <td>5500</td>
      <td>16</td>
      <td>22</td>
      <td>?</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 26 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create headers list
</span><span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s">"symboling"</span><span class="p">,</span><span class="s">"normalized-losses"</span><span class="p">,</span><span class="s">"make"</span><span class="p">,</span><span class="s">"fuel-type"</span><span class="p">,</span><span class="s">"aspiration"</span><span class="p">,</span> <span class="s">"num-of-doors"</span><span class="p">,</span><span class="s">"body-style"</span><span class="p">,</span>
         <span class="s">"drive-wheels"</span><span class="p">,</span><span class="s">"engine-location"</span><span class="p">,</span><span class="s">"wheel-base"</span><span class="p">,</span> <span class="s">"length"</span><span class="p">,</span><span class="s">"width"</span><span class="p">,</span><span class="s">"height"</span><span class="p">,</span><span class="s">"curb-weight"</span><span class="p">,</span><span class="s">"engine-type"</span><span class="p">,</span>
         <span class="s">"num-of-cylinders"</span><span class="p">,</span> <span class="s">"engine-size"</span><span class="p">,</span><span class="s">"fuel-system"</span><span class="p">,</span><span class="s">"bore"</span><span class="p">,</span><span class="s">"stroke"</span><span class="p">,</span><span class="s">"compression-ratio"</span><span class="p">,</span><span class="s">"horsepower"</span><span class="p">,</span>
         <span class="s">"peak-rpm"</span><span class="p">,</span><span class="s">"city-mpg"</span><span class="p">,</span><span class="s">"highway-mpg"</span><span class="p">,</span><span class="s">"price"</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"headers</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">headers</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>headers
 ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', 'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># replace the headers in the dataframe
</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">headers</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># view the data types
</span><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>symboling              int64
normalized-losses     object
make                  object
fuel-type             object
aspiration            object
num-of-doors          object
body-style            object
drive-wheels          object
engine-location       object
wheel-base           float64
length               float64
width                float64
height               float64
curb-weight            int64
engine-type           object
num-of-cylinders      object
engine-size            int64
fuel-system           object
bore                  object
stroke                object
compression-ratio    float64
horsepower            object
peak-rpm              object
city-mpg               int64
highway-mpg            int64
price                 object
dtype: object
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get a statistical summary of each column
</span><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>wheel-base</th>
      <th>length</th>
      <th>width</th>
      <th>height</th>
      <th>curb-weight</th>
      <th>engine-size</th>
      <th>compression-ratio</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>205.000000</td>
      <td>205.000000</td>
      <td>205.000000</td>
      <td>205.000000</td>
      <td>205.000000</td>
      <td>205.000000</td>
      <td>205.000000</td>
      <td>205.000000</td>
      <td>205.000000</td>
      <td>205.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.834146</td>
      <td>98.756585</td>
      <td>174.049268</td>
      <td>65.907805</td>
      <td>53.724878</td>
      <td>2555.565854</td>
      <td>126.907317</td>
      <td>10.142537</td>
      <td>25.219512</td>
      <td>30.751220</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.245307</td>
      <td>6.021776</td>
      <td>12.337289</td>
      <td>2.145204</td>
      <td>2.443522</td>
      <td>520.680204</td>
      <td>41.642693</td>
      <td>3.972040</td>
      <td>6.542142</td>
      <td>6.886443</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-2.000000</td>
      <td>86.600000</td>
      <td>141.100000</td>
      <td>60.300000</td>
      <td>47.800000</td>
      <td>1488.000000</td>
      <td>61.000000</td>
      <td>7.000000</td>
      <td>13.000000</td>
      <td>16.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>94.500000</td>
      <td>166.300000</td>
      <td>64.100000</td>
      <td>52.000000</td>
      <td>2145.000000</td>
      <td>97.000000</td>
      <td>8.600000</td>
      <td>19.000000</td>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>97.000000</td>
      <td>173.200000</td>
      <td>65.500000</td>
      <td>54.100000</td>
      <td>2414.000000</td>
      <td>120.000000</td>
      <td>9.000000</td>
      <td>24.000000</td>
      <td>30.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.000000</td>
      <td>102.400000</td>
      <td>183.100000</td>
      <td>66.900000</td>
      <td>55.500000</td>
      <td>2935.000000</td>
      <td>141.000000</td>
      <td>9.400000</td>
      <td>30.000000</td>
      <td>34.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.000000</td>
      <td>120.900000</td>
      <td>208.100000</td>
      <td>72.300000</td>
      <td>59.800000</td>
      <td>4066.000000</td>
      <td>326.000000</td>
      <td>23.000000</td>
      <td>49.000000</td>
      <td>54.000000</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s">'all'</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized-losses</th>
      <th>make</th>
      <th>fuel-type</th>
      <th>aspiration</th>
      <th>num-of-doors</th>
      <th>body-style</th>
      <th>drive-wheels</th>
      <th>engine-location</th>
      <th>wheel-base</th>
      <th>...</th>
      <th>engine-size</th>
      <th>fuel-system</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression-ratio</th>
      <th>horsepower</th>
      <th>peak-rpm</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>205.000000</td>
      <td>205</td>
      <td>205</td>
      <td>205</td>
      <td>205</td>
      <td>205</td>
      <td>205</td>
      <td>205</td>
      <td>205</td>
      <td>205.000000</td>
      <td>...</td>
      <td>205.000000</td>
      <td>205</td>
      <td>205</td>
      <td>205</td>
      <td>205.000000</td>
      <td>205</td>
      <td>205</td>
      <td>205.000000</td>
      <td>205.000000</td>
      <td>205</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>NaN</td>
      <td>52</td>
      <td>22</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>5</td>
      <td>3</td>
      <td>2</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>8</td>
      <td>39</td>
      <td>37</td>
      <td>NaN</td>
      <td>60</td>
      <td>24</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>187</td>
    </tr>
    <tr>
      <th>top</th>
      <td>NaN</td>
      <td>?</td>
      <td>toyota</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>mpfi</td>
      <td>3.62</td>
      <td>3.40</td>
      <td>NaN</td>
      <td>68</td>
      <td>5500</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>?</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>NaN</td>
      <td>41</td>
      <td>32</td>
      <td>185</td>
      <td>168</td>
      <td>114</td>
      <td>96</td>
      <td>120</td>
      <td>202</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>94</td>
      <td>23</td>
      <td>20</td>
      <td>NaN</td>
      <td>19</td>
      <td>37</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.834146</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>98.756585</td>
      <td>...</td>
      <td>126.907317</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>10.142537</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>25.219512</td>
      <td>30.751220</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.245307</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>6.021776</td>
      <td>...</td>
      <td>41.642693</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.972040</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>6.542142</td>
      <td>6.886443</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-2.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>86.600000</td>
      <td>...</td>
      <td>61.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>7.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13.000000</td>
      <td>16.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>94.500000</td>
      <td>...</td>
      <td>97.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>8.600000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>19.000000</td>
      <td>25.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>97.000000</td>
      <td>...</td>
      <td>120.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>24.000000</td>
      <td>30.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>102.400000</td>
      <td>...</td>
      <td>141.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9.400000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>30.000000</td>
      <td>34.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>120.900000</td>
      <td>...</td>
      <td>326.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>23.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>49.000000</td>
      <td>54.000000</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 26 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get the summary of specific columns
</span><span class="n">df</span><span class="p">[[</span><span class="s">'length'</span><span class="p">,</span> <span class="s">'compression-ratio'</span><span class="p">]].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>length</th>
      <th>compression-ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>205.000000</td>
      <td>205.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>174.049268</td>
      <td>10.142537</td>
    </tr>
    <tr>
      <th>std</th>
      <td>12.337289</td>
      <td>3.972040</td>
    </tr>
    <tr>
      <th>min</th>
      <td>141.100000</td>
      <td>7.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>166.300000</td>
      <td>8.600000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>173.200000</td>
      <td>9.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>183.100000</td>
      <td>9.400000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>208.100000</td>
      <td>23.000000</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get a concise summary (top 30 &amp; bottom 30 rows)
</span><span class="n">df</span><span class="p">.</span><span class="n">info</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;bound method DataFrame.info of      symboling normalized-losses         make fuel-type aspiration  \
0            3                 ?  alfa-romero       gas        std   
1            3                 ?  alfa-romero       gas        std   
2            1                 ?  alfa-romero       gas        std   
3            2               164         audi       gas        std   
4            2               164         audi       gas        std   
..         ...               ...          ...       ...        ...   
200         -1                95        volvo       gas        std   
201         -1                95        volvo       gas      turbo   
202         -1                95        volvo       gas        std   
203         -1                95        volvo    diesel      turbo   
204         -1                95        volvo       gas      turbo   

    num-of-doors   body-style drive-wheels engine-location  wheel-base  ...  \
0            two  convertible          rwd           front        88.6  ...   
1            two  convertible          rwd           front        88.6  ...   
2            two    hatchback          rwd           front        94.5  ...   
3           four        sedan          fwd           front        99.8  ...   
4           four        sedan          4wd           front        99.4  ...   
..           ...          ...          ...             ...         ...  ...   
200         four        sedan          rwd           front       109.1  ...   
201         four        sedan          rwd           front       109.1  ...   
202         four        sedan          rwd           front       109.1  ...   
203         four        sedan          rwd           front       109.1  ...   
204         four        sedan          rwd           front       109.1  ...   

     engine-size  fuel-system  bore  stroke compression-ratio horsepower  \
0            130         mpfi  3.47    2.68               9.0        111   
1            130         mpfi  3.47    2.68               9.0        111   
2            152         mpfi  2.68    3.47               9.0        154   
3            109         mpfi  3.19    3.40              10.0        102   
4            136         mpfi  3.19    3.40               8.0        115   
..           ...          ...   ...     ...               ...        ...   
200          141         mpfi  3.78    3.15               9.5        114   
201          141         mpfi  3.78    3.15               8.7        160   
202          173         mpfi  3.58    2.87               8.8        134   
203          145          idi  3.01    3.40              23.0        106   
204          141         mpfi  3.78    3.15               9.5        114   

     peak-rpm city-mpg highway-mpg  price  
0        5000       21          27  13495  
1        5000       21          27  16500  
2        5000       19          26  16500  
3        5500       24          30  13950  
4        5500       18          22  17450  
..        ...      ...         ...    ...  
200      5400       23          28  16845  
201      5300       19          25  19045  
202      5500       18          23  21485  
203      4800       26          27  22470  
204      5400       19          25  22625  

[205 rows x 26 columns]&gt;
</code></pre></div></div>

<h2 id="data-wrangling">
<a class="anchor" href="#data-wrangling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Wrangling</h2>
<p>Data Wrangling is the process of converting data from the initial format to a format that may be better for analysis.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># replace "?" with NaN
</span><span class="n">df</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'?'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># identify the missing data
# use ".isnull()" or ".notnull()"
</span><span class="n">missing_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">isnull</span><span class="p">()</span> <span class="c1"># True stands for missing value
</span><span class="n">missing_data</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized-losses</th>
      <th>make</th>
      <th>fuel-type</th>
      <th>aspiration</th>
      <th>num-of-doors</th>
      <th>body-style</th>
      <th>drive-wheels</th>
      <th>engine-location</th>
      <th>wheel-base</th>
      <th>...</th>
      <th>engine-size</th>
      <th>fuel-system</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression-ratio</th>
      <th>horsepower</th>
      <th>peak-rpm</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>7</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>9</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 26 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># count the missing values in each column
</span><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">missing_data</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="n">tolist</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">missing_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">value_counts</span><span class="p">())</span>
    <span class="k">print</span><span class="p">(</span><span class="s">""</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>symboling
False    205
Name: symboling, dtype: int64

normalized-losses
False    164
True      41
Name: normalized-losses, dtype: int64

make
False    205
Name: make, dtype: int64

fuel-type
False    205
Name: fuel-type, dtype: int64

aspiration
False    205
Name: aspiration, dtype: int64

num-of-doors
False    203
True       2
Name: num-of-doors, dtype: int64

body-style
False    205
Name: body-style, dtype: int64

drive-wheels
False    205
Name: drive-wheels, dtype: int64

engine-location
False    205
Name: engine-location, dtype: int64

wheel-base
False    205
Name: wheel-base, dtype: int64

length
False    205
Name: length, dtype: int64

width
False    205
Name: width, dtype: int64

height
False    205
Name: height, dtype: int64

curb-weight
False    205
Name: curb-weight, dtype: int64

engine-type
False    205
Name: engine-type, dtype: int64

num-of-cylinders
False    205
Name: num-of-cylinders, dtype: int64

engine-size
False    205
Name: engine-size, dtype: int64

fuel-system
False    205
Name: fuel-system, dtype: int64

bore
False    201
True       4
Name: bore, dtype: int64

stroke
False    201
True       4
Name: stroke, dtype: int64

compression-ratio
False    205
Name: compression-ratio, dtype: int64

horsepower
False    203
True       2
Name: horsepower, dtype: int64

peak-rpm
False    203
True       2
Name: peak-rpm, dtype: int64

city-mpg
False    205
Name: city-mpg, dtype: int64

highway-mpg
False    205
Name: highway-mpg, dtype: int64

price
False    201
True       4
Name: price, dtype: int64
</code></pre></div></div>

<p>In this dataset, none of the columns are empty enough to drop entirely.</p>

<p><strong>Replace by mean:</strong><br>
“normalized-losses”: 41 missing data, replace them with mean<br>
“bore”: 4 missing data, replace them with mean<br>
“stroke”: 4 missing data, replace them with mean<br>
“horsepower”: 2 missing data, replace them with mean<br>
“peak-rpm”: 2 missing data, replace them with mean</p>

<p><strong>Replace by frequency:</strong><br>
“num-of-doors”: 2 missing data, replace them with “four”<br>
Reason: 84% sedans are four-door. Since four doors is most frequent, it is most likely to occur</p>

<p><strong>Drop the whole row:</strong><br>
“price”: 4 missing data, simply delete the whole row<br>
Reason: Price is what we want to predict. Any data entry without price data cannot be used for prediction; therefore any row now without price data is not useful to us.</p>

<h5 id="replace-by-mean">
<a class="anchor" href="#replace-by-mean" aria-hidden="true"><span class="octicon octicon-link"></span></a>Replace by mean</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># normalized-losses column
# calculate average of the column. astype('float') saves the mean value in float dtype.
</span><span class="n">avg_norm_loss</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'normalized-losses'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">).</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average of normalized-losses:'</span><span class="p">,</span> <span class="n">avg_norm_loss</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average of normalized-losses: 122.0
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># normalized-losses column
# replace NaN by the mean value
</span><span class="n">df</span><span class="p">[</span><span class="s">'normalized-losses'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">avg_norm_loss</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># bore column
# calculate average of the column. astype('float') saves the mean value in float dtype.
</span><span class="n">avg_bore</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'bore'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">).</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average of bore:'</span><span class="p">,</span> <span class="n">avg_bore</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average of bore: 3.3297512437810957
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># bore column
# replace NaN by the mean value
</span><span class="n">df</span><span class="p">[</span><span class="s">'bore'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">avg_norm_loss</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># stroke column
# calculate average of the column. astype('float') saves the mean value in float dtype.
</span><span class="n">avg_stroke</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'stroke'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">).</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average of stroke:'</span><span class="p">,</span> <span class="n">avg_stroke</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average of stroke: 3.2554228855721337
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># stroke column
# replace NaN by the mean value
</span><span class="n">df</span><span class="p">[</span><span class="s">'stroke'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">avg_stroke</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># horsepower column
# calculate average of the column. astpye('float') saves the mean value in flaot dtype
</span><span class="n">avg_hp</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">).</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average of horsepower: '</span><span class="p">,</span> <span class="n">avg_hp</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average of horsepower:  104.25615763546799
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># horsepower column
# replace NaN by the ean value
</span><span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">avg_hp</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># peak-rpm column
# calculate average of the column. astype('float') saves the mean value in float dtype.
</span><span class="n">avg_peakrpm</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'peak-rpm'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">).</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average of peak-rpm:'</span><span class="p">,</span> <span class="n">avg_peakrpm</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average of peak-rpm: 5125.369458128079
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># peak-rpm column
# replace NaN by the mean value
</span><span class="n">df</span><span class="p">[</span><span class="s">'peak-rpm'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">avg_peakrpm</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="replace-by-frequency">
<a class="anchor" href="#replace-by-frequency" aria-hidden="true"><span class="octicon octicon-link"></span></a>Replace by Frequency</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># identify which values are present in a particular column
</span><span class="n">df</span><span class="p">[</span><span class="s">'num-of-doors'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>four    114
two      89
Name: num-of-doors, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use the ".idxmax()" method to calculate for us the most common type automatically
</span><span class="n">df</span><span class="p">[</span><span class="s">'num-of-doors'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">idxmax</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'four'
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># replace the missing 'num-of-doors' values by the most frequent
</span><span class="n">df</span><span class="p">[</span><span class="s">'num-of-doors'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="s">'four'</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="drop-the-whole-row">
<a class="anchor" href="#drop-the-whole-row" aria-hidden="true"><span class="octicon octicon-link"></span></a>Drop the whole row</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># reset the index because we dropped rows
</span><span class="n">df</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized-losses</th>
      <th>make</th>
      <th>fuel-type</th>
      <th>aspiration</th>
      <th>num-of-doors</th>
      <th>body-style</th>
      <th>drive-wheels</th>
      <th>engine-location</th>
      <th>wheel-base</th>
      <th>...</th>
      <th>engine-size</th>
      <th>fuel-system</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression-ratio</th>
      <th>horsepower</th>
      <th>peak-rpm</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>122</td>
      <td>alfa-romero</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>convertible</td>
      <td>rwd</td>
      <td>front</td>
      <td>88.6</td>
      <td>...</td>
      <td>130</td>
      <td>mpfi</td>
      <td>3.47</td>
      <td>2.68</td>
      <td>9.0</td>
      <td>111</td>
      <td>5000</td>
      <td>21</td>
      <td>27</td>
      <td>13495</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>122</td>
      <td>alfa-romero</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>convertible</td>
      <td>rwd</td>
      <td>front</td>
      <td>88.6</td>
      <td>...</td>
      <td>130</td>
      <td>mpfi</td>
      <td>3.47</td>
      <td>2.68</td>
      <td>9.0</td>
      <td>111</td>
      <td>5000</td>
      <td>21</td>
      <td>27</td>
      <td>16500</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>122</td>
      <td>alfa-romero</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>hatchback</td>
      <td>rwd</td>
      <td>front</td>
      <td>94.5</td>
      <td>...</td>
      <td>152</td>
      <td>mpfi</td>
      <td>2.68</td>
      <td>3.47</td>
      <td>9.0</td>
      <td>154</td>
      <td>5000</td>
      <td>19</td>
      <td>26</td>
      <td>16500</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>164</td>
      <td>audi</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>99.8</td>
      <td>...</td>
      <td>109</td>
      <td>mpfi</td>
      <td>3.19</td>
      <td>3.40</td>
      <td>10.0</td>
      <td>102</td>
      <td>5500</td>
      <td>24</td>
      <td>30</td>
      <td>13950</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>164</td>
      <td>audi</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>4wd</td>
      <td>front</td>
      <td>99.4</td>
      <td>...</td>
      <td>136</td>
      <td>mpfi</td>
      <td>3.19</td>
      <td>3.40</td>
      <td>8.0</td>
      <td>115</td>
      <td>5500</td>
      <td>18</td>
      <td>22</td>
      <td>17450</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 26 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># check the data types
</span><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>symboling              int64
normalized-losses     object
make                  object
fuel-type             object
aspiration            object
num-of-doors          object
body-style            object
drive-wheels          object
engine-location       object
wheel-base           float64
length               float64
width                float64
height               float64
curb-weight            int64
engine-type           object
num-of-cylinders      object
engine-size            int64
fuel-system           object
bore                  object
stroke                object
compression-ratio    float64
horsepower            object
peak-rpm              object
city-mpg               int64
highway-mpg            int64
price                 object
dtype: object
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the data types into proper format
# use double brackets when including multiple columns in one statement
</span><span class="n">df</span><span class="p">[[</span><span class="s">'bore'</span><span class="p">,</span> <span class="s">'stroke'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">,</span> <span class="s">'peak-rpm'</span><span class="p">,</span> <span class="s">'horsepower'</span><span class="p">]]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'bore'</span><span class="p">,</span> <span class="s">'stroke'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">,</span> <span class="s">'peak-rpm'</span><span class="p">,</span> <span class="s">'horsepower'</span><span class="p">]].</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'normalized-losses'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'normalized-losses'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'int'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>symboling              int64
normalized-losses      int32
make                  object
fuel-type             object
aspiration            object
num-of-doors          object
body-style            object
drive-wheels          object
engine-location       object
wheel-base           float64
length               float64
width                float64
height               float64
curb-weight            int64
engine-type           object
num-of-cylinders      object
engine-size            int64
fuel-system           object
bore                 float64
stroke               float64
compression-ratio    float64
horsepower           float64
peak-rpm             float64
city-mpg               int64
highway-mpg            int64
price                float64
dtype: object
</code></pre></div></div>

<h2 id="data-normalization">
<a class="anchor" href="#data-normalization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Normalization</h2>
<p>Normalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or scaling variable so the variable values range from 0 to 1.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># scale the columns 'length', 'width' and 'height'
# replace (original value) by (original value)/(maximum value)
</span><span class="n">df</span><span class="p">[</span><span class="s">'length'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'length'</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="p">[</span><span class="s">'length'</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s">'width'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'width'</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="p">[</span><span class="s">'width'</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s">'height'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'height'</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="p">[</span><span class="s">'height'</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span>

<span class="n">df</span><span class="p">[[</span><span class="s">'length'</span><span class="p">,</span> <span class="s">'width'</span><span class="p">,</span> <span class="s">'height'</span><span class="p">]].</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>length</th>
      <th>width</th>
      <th>height</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.811148</td>
      <td>0.890278</td>
      <td>0.816054</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.811148</td>
      <td>0.890278</td>
      <td>0.816054</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.822681</td>
      <td>0.909722</td>
      <td>0.876254</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.848630</td>
      <td>0.919444</td>
      <td>0.908027</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.848630</td>
      <td>0.922222</td>
      <td>0.908027</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="binning">
<a class="anchor" href="#binning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Binning</h3>
<p>Binning is a process of transforming continuous numerical variables into discrete categorical ‘bins’, for grouped analysis.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count    201.000000
mean     103.405534
std       37.365700
min       48.000000
25%       70.000000
50%       95.000000
75%      116.000000
max      262.000000
Name: horsepower, dtype: float64
</code></pre></div></div>

<p>In our dataset, “horsepower” is a real valued variable ranging from 48 to 288, it has 58 unique values. What if we only care about the price difference between cars with high horsepower, medium horsepower, and little horsepower (3 types)?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"horsepower"</span><span class="p">])</span>

<span class="c1"># set x/y labels and plot title
</span><span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"horsepower"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"horsepower bins"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'horsepower bins')
</code></pre></div></div>

<!-- <img src="/assets/img/dataAnalysisWithPython/output_40_1.png"> -->

<p><img src="/ai/images/dataAnalysisWithPython/output_40_1.png" alt=""></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">]),</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">bins</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([ 48.        , 119.33333333, 190.66666667, 262.        ])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set the group names
</span><span class="n">group_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'low'</span><span class="p">,</span> <span class="s">'medium'</span><span class="p">,</span> <span class="s">'high'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'horsepower-binned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">],</span> <span class="n">bins</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">group_names</span><span class="p">,</span> <span class="n">include_lowest</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'horsepower-binned'</span><span class="p">]].</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>horsepower</th>
      <th>horsepower-binned</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>111.0</td>
      <td>low</td>
    </tr>
    <tr>
      <th>1</th>
      <td>111.0</td>
      <td>low</td>
    </tr>
    <tr>
      <th>2</th>
      <td>154.0</td>
      <td>medium</td>
    </tr>
    <tr>
      <th>3</th>
      <td>102.0</td>
      <td>low</td>
    </tr>
    <tr>
      <th>4</th>
      <td>115.0</td>
      <td>low</td>
    </tr>
    <tr>
      <th>5</th>
      <td>110.0</td>
      <td>low</td>
    </tr>
    <tr>
      <th>6</th>
      <td>110.0</td>
      <td>low</td>
    </tr>
    <tr>
      <th>7</th>
      <td>110.0</td>
      <td>low</td>
    </tr>
    <tr>
      <th>8</th>
      <td>140.0</td>
      <td>medium</td>
    </tr>
    <tr>
      <th>9</th>
      <td>101.0</td>
      <td>low</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'horsepower-binned'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>low       153
medium     43
high        5
Name: horsepower-binned, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot the distribution
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">group_names</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"horsepower-binned"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">())</span>

<span class="c1"># set x/y labels and plot title
</span><span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"horsepower"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"horsepower bins"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'horsepower bins')
</code></pre></div></div>

<!-- 
<img src = "/assets/img/dataAnalysisWithPython/output_45_1.png"> -->
<p><img src="/ai/images/dataAnalysisWithPython/output_45_1.png%22" alt=""></p>

<h4 id="bins-visualization">
<a class="anchor" href="#bins-visualization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bins Visualization</h4>
<p>Normally, a histogram is used to visualize the distribution of bins.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>

<span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># draw histogram of attribute 'horsepower' with bins=3
</span><span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># set x/y labels and plot title
</span><span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'horsepower'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'count'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'horsepower bins'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'horsepower bins')
</code></pre></div></div>

<!-- <img src = "/assets/img/dataAnalysisWithPython/output_47_1.png"> -->
<p><img src="/ai/images/dataAnalysisWithPython/output_47_1.png%22" alt=""></p>

<h4 id="indicator-variable-or-dummy-variable">
<a class="anchor" href="#indicator-variable-or-dummy-variable" aria-hidden="true"><span class="octicon octicon-link"></span></a>Indicator variable (or dummy variable)</h4>
<p>An indicator variable (or dummy variable) is a numerical variable used to label categories. They are called ‘dummies’ because the numbers themselves don’t have inherent meaning.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'fuel-type'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['gas', 'diesel'], dtype=object)
</code></pre></div></div>

<p>We see the column “fuel-type” has two unique values, “gas” or “diesel”. Regression doesn’t understand words, only numbers. To use this attribute in regression analysis, we convert “fuel-type” into indicator variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># assign numerical values to the different categories of 'fuel-tpye'
</span><span class="n">dummy_variable_1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'fuel-type'</span><span class="p">])</span>
<span class="n">dummy_variable_1</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>diesel</th>
      <th>gas</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration',
       'num-of-doors', 'body-style', 'drive-wheels', 'engine-location',
       'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type',
       'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke',
       'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',
       'highway-mpg', 'price', 'horsepower-binned'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># change column names for clarity
</span><span class="n">dummy_variable_1</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'fuel-tpye-diesel'</span><span class="p">:</span><span class="s">'gas'</span><span class="p">,</span> <span class="s">'fuel-type-diesel'</span><span class="p">:</span><span class="s">'diesel'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dummy_variable_1</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>diesel</th>
      <th>gas</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration',
       'num-of-doors', 'body-style', 'drive-wheels', 'engine-location',
       'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type',
       'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke',
       'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',
       'highway-mpg', 'price', 'horsepower-binned'],
      dtype='object')
</code></pre></div></div>

<p>We now have the value 0 to represent “gas” and 1 to represent “diesel” in the column “fuel-type”.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># merge data frame 'df' and 'dummy_variable_1'
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">dummy_variable_1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># drop original column 'fuel-type' from 'df'
</span><span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'fuel-type'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>The last two columns are now the indicator variable representation of the fuel-type variable. It’s all 0s and 1s now.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create indicator variable for the column 'aspiration'
</span><span class="n">dummy_variable_2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'aspiration'</span><span class="p">])</span>
<span class="n">dummy_variable_2</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'std'</span><span class="p">:</span> <span class="s">'aspiration-std'</span><span class="p">,</span> <span class="s">'turbo'</span><span class="p">:</span> <span class="s">'aspiration-turbo'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dummy_variable_2</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aspiration-std</th>
      <th>aspiration-turbo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># merge the new dataframe to the original dataframe
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">dummy_variable_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># drop the column 'aspiration'
</span><span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'aspiration'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized-losses</th>
      <th>make</th>
      <th>num-of-doors</th>
      <th>body-style</th>
      <th>drive-wheels</th>
      <th>engine-location</th>
      <th>wheel-base</th>
      <th>length</th>
      <th>width</th>
      <th>...</th>
      <th>horsepower</th>
      <th>peak-rpm</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
      <th>price</th>
      <th>horsepower-binned</th>
      <th>diesel</th>
      <th>gas</th>
      <th>aspiration-std</th>
      <th>aspiration-turbo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>122</td>
      <td>alfa-romero</td>
      <td>two</td>
      <td>convertible</td>
      <td>rwd</td>
      <td>front</td>
      <td>88.6</td>
      <td>0.811148</td>
      <td>0.890278</td>
      <td>...</td>
      <td>111.0</td>
      <td>5000.0</td>
      <td>21</td>
      <td>27</td>
      <td>13495.0</td>
      <td>low</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>122</td>
      <td>alfa-romero</td>
      <td>two</td>
      <td>convertible</td>
      <td>rwd</td>
      <td>front</td>
      <td>88.6</td>
      <td>0.811148</td>
      <td>0.890278</td>
      <td>...</td>
      <td>111.0</td>
      <td>5000.0</td>
      <td>21</td>
      <td>27</td>
      <td>16500.0</td>
      <td>low</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>122</td>
      <td>alfa-romero</td>
      <td>two</td>
      <td>hatchback</td>
      <td>rwd</td>
      <td>front</td>
      <td>94.5</td>
      <td>0.822681</td>
      <td>0.909722</td>
      <td>...</td>
      <td>154.0</td>
      <td>5000.0</td>
      <td>19</td>
      <td>26</td>
      <td>16500.0</td>
      <td>medium</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>164</td>
      <td>audi</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>99.8</td>
      <td>0.848630</td>
      <td>0.919444</td>
      <td>...</td>
      <td>102.0</td>
      <td>5500.0</td>
      <td>24</td>
      <td>30</td>
      <td>13950.0</td>
      <td>low</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>164</td>
      <td>audi</td>
      <td>four</td>
      <td>sedan</td>
      <td>4wd</td>
      <td>front</td>
      <td>99.4</td>
      <td>0.848630</td>
      <td>0.922222</td>
      <td>...</td>
      <td>115.0</td>
      <td>5500.0</td>
      <td>18</td>
      <td>22</td>
      <td>17450.0</td>
      <td>low</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 29 columns</p>
</div>

<h3 id="analyzing-individual-feature-patterns-using-visualization">
<a class="anchor" href="#analyzing-individual-feature-patterns-using-visualization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analyzing Individual Feature Patterns using Visualization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span> 
</code></pre></div></div>

<h4 id="continuous-numerical-variables">
<a class="anchor" href="#continuous-numerical-variables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Continuous numerical variables</h4>
<p>Continuous numerical variables are variables that may contain any value within some range. Continuous numerical variables can have the type “int64” or “float64”. A great way to visualize these variables is by using scatterplots with fitted lines.</p>

<h4 id="correlation">
<a class="anchor" href="#correlation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Correlation</h4>
<p>We can calculate the correlation between variables of type ‘int64’ or ‘float64’ using the method ‘corr’.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span> 
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized-losses</th>
      <th>wheel-base</th>
      <th>length</th>
      <th>width</th>
      <th>height</th>
      <th>curb-weight</th>
      <th>engine-size</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression-ratio</th>
      <th>horsepower</th>
      <th>peak-rpm</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
      <th>price</th>
      <th>diesel</th>
      <th>gas</th>
      <th>aspiration-std</th>
      <th>aspiration-turbo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>symboling</th>
      <td>1.000000</td>
      <td>0.466264</td>
      <td>-0.535987</td>
      <td>-0.365404</td>
      <td>-0.242423</td>
      <td>-0.550160</td>
      <td>-0.233118</td>
      <td>-0.110581</td>
      <td>0.243521</td>
      <td>-0.008153</td>
      <td>-0.182196</td>
      <td>0.075819</td>
      <td>0.279740</td>
      <td>-0.035527</td>
      <td>0.036233</td>
      <td>-0.082391</td>
      <td>-0.196735</td>
      <td>0.196735</td>
      <td>0.054615</td>
      <td>-0.054615</td>
    </tr>
    <tr>
      <th>normalized-losses</th>
      <td>0.466264</td>
      <td>1.000000</td>
      <td>-0.056661</td>
      <td>0.019424</td>
      <td>0.086802</td>
      <td>-0.373737</td>
      <td>0.099404</td>
      <td>0.112360</td>
      <td>0.124511</td>
      <td>0.055045</td>
      <td>-0.114713</td>
      <td>0.217299</td>
      <td>0.239543</td>
      <td>-0.225016</td>
      <td>-0.181877</td>
      <td>0.133999</td>
      <td>-0.101546</td>
      <td>0.101546</td>
      <td>0.006911</td>
      <td>-0.006911</td>
    </tr>
    <tr>
      <th>wheel-base</th>
      <td>-0.535987</td>
      <td>-0.056661</td>
      <td>1.000000</td>
      <td>0.876024</td>
      <td>0.814507</td>
      <td>0.590742</td>
      <td>0.782097</td>
      <td>0.572027</td>
      <td>-0.074380</td>
      <td>0.158018</td>
      <td>0.250313</td>
      <td>0.371147</td>
      <td>-0.360305</td>
      <td>-0.470606</td>
      <td>-0.543304</td>
      <td>0.584642</td>
      <td>0.307237</td>
      <td>-0.307237</td>
      <td>-0.256889</td>
      <td>0.256889</td>
    </tr>
    <tr>
      <th>length</th>
      <td>-0.365404</td>
      <td>0.019424</td>
      <td>0.876024</td>
      <td>1.000000</td>
      <td>0.857170</td>
      <td>0.492063</td>
      <td>0.880665</td>
      <td>0.685025</td>
      <td>-0.050463</td>
      <td>0.123952</td>
      <td>0.159733</td>
      <td>0.579821</td>
      <td>-0.285970</td>
      <td>-0.665192</td>
      <td>-0.698142</td>
      <td>0.690628</td>
      <td>0.211187</td>
      <td>-0.211187</td>
      <td>-0.230085</td>
      <td>0.230085</td>
    </tr>
    <tr>
      <th>width</th>
      <td>-0.242423</td>
      <td>0.086802</td>
      <td>0.814507</td>
      <td>0.857170</td>
      <td>1.000000</td>
      <td>0.306002</td>
      <td>0.866201</td>
      <td>0.729436</td>
      <td>-0.004059</td>
      <td>0.188822</td>
      <td>0.189867</td>
      <td>0.615077</td>
      <td>-0.245800</td>
      <td>-0.633531</td>
      <td>-0.680635</td>
      <td>0.751265</td>
      <td>0.244356</td>
      <td>-0.244356</td>
      <td>-0.305732</td>
      <td>0.305732</td>
    </tr>
    <tr>
      <th>height</th>
      <td>-0.550160</td>
      <td>-0.373737</td>
      <td>0.590742</td>
      <td>0.492063</td>
      <td>0.306002</td>
      <td>1.000000</td>
      <td>0.307581</td>
      <td>0.074694</td>
      <td>-0.240217</td>
      <td>-0.060663</td>
      <td>0.259737</td>
      <td>-0.087027</td>
      <td>-0.309974</td>
      <td>-0.049800</td>
      <td>-0.104812</td>
      <td>0.135486</td>
      <td>0.281578</td>
      <td>-0.281578</td>
      <td>-0.090336</td>
      <td>0.090336</td>
    </tr>
    <tr>
      <th>curb-weight</th>
      <td>-0.233118</td>
      <td>0.099404</td>
      <td>0.782097</td>
      <td>0.880665</td>
      <td>0.866201</td>
      <td>0.307581</td>
      <td>1.000000</td>
      <td>0.849072</td>
      <td>-0.029485</td>
      <td>0.167438</td>
      <td>0.156433</td>
      <td>0.757976</td>
      <td>-0.279361</td>
      <td>-0.749543</td>
      <td>-0.794889</td>
      <td>0.834415</td>
      <td>0.221046</td>
      <td>-0.221046</td>
      <td>-0.321955</td>
      <td>0.321955</td>
    </tr>
    <tr>
      <th>engine-size</th>
      <td>-0.110581</td>
      <td>0.112360</td>
      <td>0.572027</td>
      <td>0.685025</td>
      <td>0.729436</td>
      <td>0.074694</td>
      <td>0.849072</td>
      <td>1.000000</td>
      <td>-0.177698</td>
      <td>0.205928</td>
      <td>0.028889</td>
      <td>0.822676</td>
      <td>-0.256733</td>
      <td>-0.650546</td>
      <td>-0.679571</td>
      <td>0.872335</td>
      <td>0.070779</td>
      <td>-0.070779</td>
      <td>-0.110040</td>
      <td>0.110040</td>
    </tr>
    <tr>
      <th>bore</th>
      <td>0.243521</td>
      <td>0.124511</td>
      <td>-0.074380</td>
      <td>-0.050463</td>
      <td>-0.004059</td>
      <td>-0.240217</td>
      <td>-0.029485</td>
      <td>-0.177698</td>
      <td>1.000000</td>
      <td>-0.001549</td>
      <td>-0.027237</td>
      <td>0.032443</td>
      <td>0.259276</td>
      <td>-0.196827</td>
      <td>-0.170635</td>
      <td>0.005399</td>
      <td>-0.046482</td>
      <td>0.046482</td>
      <td>0.062876</td>
      <td>-0.062876</td>
    </tr>
    <tr>
      <th>stroke</th>
      <td>-0.008153</td>
      <td>0.055045</td>
      <td>0.158018</td>
      <td>0.123952</td>
      <td>0.188822</td>
      <td>-0.060663</td>
      <td>0.167438</td>
      <td>0.205928</td>
      <td>-0.001549</td>
      <td>1.000000</td>
      <td>0.187871</td>
      <td>0.098267</td>
      <td>-0.063561</td>
      <td>-0.033956</td>
      <td>-0.034636</td>
      <td>0.082269</td>
      <td>0.241064</td>
      <td>-0.241064</td>
      <td>-0.218233</td>
      <td>0.218233</td>
    </tr>
    <tr>
      <th>compression-ratio</th>
      <td>-0.182196</td>
      <td>-0.114713</td>
      <td>0.250313</td>
      <td>0.159733</td>
      <td>0.189867</td>
      <td>0.259737</td>
      <td>0.156433</td>
      <td>0.028889</td>
      <td>-0.027237</td>
      <td>0.187871</td>
      <td>1.000000</td>
      <td>-0.214514</td>
      <td>-0.435780</td>
      <td>0.331425</td>
      <td>0.268465</td>
      <td>0.071107</td>
      <td>0.985231</td>
      <td>-0.985231</td>
      <td>-0.307522</td>
      <td>0.307522</td>
    </tr>
    <tr>
      <th>horsepower</th>
      <td>0.075819</td>
      <td>0.217299</td>
      <td>0.371147</td>
      <td>0.579821</td>
      <td>0.615077</td>
      <td>-0.087027</td>
      <td>0.757976</td>
      <td>0.822676</td>
      <td>0.032443</td>
      <td>0.098267</td>
      <td>-0.214514</td>
      <td>1.000000</td>
      <td>0.107885</td>
      <td>-0.822214</td>
      <td>-0.804575</td>
      <td>0.809575</td>
      <td>-0.169053</td>
      <td>0.169053</td>
      <td>-0.251127</td>
      <td>0.251127</td>
    </tr>
    <tr>
      <th>peak-rpm</th>
      <td>0.279740</td>
      <td>0.239543</td>
      <td>-0.360305</td>
      <td>-0.285970</td>
      <td>-0.245800</td>
      <td>-0.309974</td>
      <td>-0.279361</td>
      <td>-0.256733</td>
      <td>0.259276</td>
      <td>-0.063561</td>
      <td>-0.435780</td>
      <td>0.107885</td>
      <td>1.000000</td>
      <td>-0.115413</td>
      <td>-0.058598</td>
      <td>-0.101616</td>
      <td>-0.475812</td>
      <td>0.475812</td>
      <td>0.190057</td>
      <td>-0.190057</td>
    </tr>
    <tr>
      <th>city-mpg</th>
      <td>-0.035527</td>
      <td>-0.225016</td>
      <td>-0.470606</td>
      <td>-0.665192</td>
      <td>-0.633531</td>
      <td>-0.049800</td>
      <td>-0.749543</td>
      <td>-0.650546</td>
      <td>-0.196827</td>
      <td>-0.033956</td>
      <td>0.331425</td>
      <td>-0.822214</td>
      <td>-0.115413</td>
      <td>1.000000</td>
      <td>0.972044</td>
      <td>-0.686571</td>
      <td>0.265676</td>
      <td>-0.265676</td>
      <td>0.189237</td>
      <td>-0.189237</td>
    </tr>
    <tr>
      <th>highway-mpg</th>
      <td>0.036233</td>
      <td>-0.181877</td>
      <td>-0.543304</td>
      <td>-0.698142</td>
      <td>-0.680635</td>
      <td>-0.104812</td>
      <td>-0.794889</td>
      <td>-0.679571</td>
      <td>-0.170635</td>
      <td>-0.034636</td>
      <td>0.268465</td>
      <td>-0.804575</td>
      <td>-0.058598</td>
      <td>0.972044</td>
      <td>1.000000</td>
      <td>-0.704692</td>
      <td>0.198690</td>
      <td>-0.198690</td>
      <td>0.241851</td>
      <td>-0.241851</td>
    </tr>
    <tr>
      <th>price</th>
      <td>-0.082391</td>
      <td>0.133999</td>
      <td>0.584642</td>
      <td>0.690628</td>
      <td>0.751265</td>
      <td>0.135486</td>
      <td>0.834415</td>
      <td>0.872335</td>
      <td>0.005399</td>
      <td>0.082269</td>
      <td>0.071107</td>
      <td>0.809575</td>
      <td>-0.101616</td>
      <td>-0.686571</td>
      <td>-0.704692</td>
      <td>1.000000</td>
      <td>0.110326</td>
      <td>-0.110326</td>
      <td>-0.179578</td>
      <td>0.179578</td>
    </tr>
    <tr>
      <th>diesel</th>
      <td>-0.196735</td>
      <td>-0.101546</td>
      <td>0.307237</td>
      <td>0.211187</td>
      <td>0.244356</td>
      <td>0.281578</td>
      <td>0.221046</td>
      <td>0.070779</td>
      <td>-0.046482</td>
      <td>0.241064</td>
      <td>0.985231</td>
      <td>-0.169053</td>
      <td>-0.475812</td>
      <td>0.265676</td>
      <td>0.198690</td>
      <td>0.110326</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>-0.408228</td>
      <td>0.408228</td>
    </tr>
    <tr>
      <th>gas</th>
      <td>0.196735</td>
      <td>0.101546</td>
      <td>-0.307237</td>
      <td>-0.211187</td>
      <td>-0.244356</td>
      <td>-0.281578</td>
      <td>-0.221046</td>
      <td>-0.070779</td>
      <td>0.046482</td>
      <td>-0.241064</td>
      <td>-0.985231</td>
      <td>0.169053</td>
      <td>0.475812</td>
      <td>-0.265676</td>
      <td>-0.198690</td>
      <td>-0.110326</td>
      <td>-1.000000</td>
      <td>1.000000</td>
      <td>0.408228</td>
      <td>-0.408228</td>
    </tr>
    <tr>
      <th>aspiration-std</th>
      <td>0.054615</td>
      <td>0.006911</td>
      <td>-0.256889</td>
      <td>-0.230085</td>
      <td>-0.305732</td>
      <td>-0.090336</td>
      <td>-0.321955</td>
      <td>-0.110040</td>
      <td>0.062876</td>
      <td>-0.218233</td>
      <td>-0.307522</td>
      <td>-0.251127</td>
      <td>0.190057</td>
      <td>0.189237</td>
      <td>0.241851</td>
      <td>-0.179578</td>
      <td>-0.408228</td>
      <td>0.408228</td>
      <td>1.000000</td>
      <td>-1.000000</td>
    </tr>
    <tr>
      <th>aspiration-turbo</th>
      <td>-0.054615</td>
      <td>-0.006911</td>
      <td>0.256889</td>
      <td>0.230085</td>
      <td>0.305732</td>
      <td>0.090336</td>
      <td>0.321955</td>
      <td>0.110040</td>
      <td>-0.062876</td>
      <td>0.218233</td>
      <td>0.307522</td>
      <td>0.251127</td>
      <td>-0.190057</td>
      <td>-0.189237</td>
      <td>-0.241851</td>
      <td>0.179578</td>
      <td>0.408228</td>
      <td>-0.408228</td>
      <td>-1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># correlation between bore, stroke, compression-ratio and horspower
</span><span class="n">df</span><span class="p">[[</span><span class="s">'bore'</span><span class="p">,</span> <span class="s">'stroke'</span><span class="p">,</span> <span class="s">'compression-ratio'</span><span class="p">,</span> <span class="s">'horsepower'</span><span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression-ratio</th>
      <th>horsepower</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bore</th>
      <td>1.000000</td>
      <td>-0.001549</td>
      <td>-0.027237</td>
      <td>0.032443</td>
    </tr>
    <tr>
      <th>stroke</th>
      <td>-0.001549</td>
      <td>1.000000</td>
      <td>0.187871</td>
      <td>0.098267</td>
    </tr>
    <tr>
      <th>compression-ratio</th>
      <td>-0.027237</td>
      <td>0.187871</td>
      <td>1.000000</td>
      <td>-0.214514</td>
    </tr>
    <tr>
      <th>horsepower</th>
      <td>0.032443</td>
      <td>0.098267</td>
      <td>-0.214514</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="continuos-numerical-variables">
<a class="anchor" href="#continuos-numerical-variables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Continuos numerical variables</h3>
<p>Continuous numerical variables are variables that may contain any value within some range. Continuous numerical variables can have the type “int64” or “float64”. A great way to visualize these variables is by using scatterplots with fitted lines.</p>

<h5 id="positive-linear-relationship">
<a class="anchor" href="#positive-linear-relationship" aria-hidden="true"><span class="octicon octicon-link"></span></a>Positive Linear Relationship</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># engine size as potential predictor variable of price
</span><span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'engine-size'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0, 53229.620270856)
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_66_1.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_66_1.png"> --></p>

<p>As the engine-size goes up, the price goes up: this indicates a positive direct correlation between these two variables. Engine size seems like a pretty good predictor of price since the regression line is almost a perfect diagonal line.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># examine the correlation between 'engine-size' and 'price'
</span><span class="n">df</span><span class="p">[[</span><span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>engine-size</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>engine-size</th>
      <td>1.000000</td>
      <td>0.872335</td>
    </tr>
    <tr>
      <th>price</th>
      <td>0.872335</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>As the highway-mpg goes up, the price goes down: this indicates an inverse/negative relationship between these two variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># examine the correlation between 'highway-mpg' and 'price'
</span><span class="n">df</span><span class="p">[[</span><span class="s">'highway-mpg'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>highway-mpg</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>highway-mpg</th>
      <td>1.000000</td>
      <td>-0.704692</td>
    </tr>
    <tr>
      <th>price</th>
      <td>-0.704692</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<h5 id="weak-linear-relationship">
<a class="anchor" href="#weak-linear-relationship" aria-hidden="true"><span class="octicon octicon-link"></span></a>Weak Linear Relationship</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># relationship between peak-rpm and price
</span><span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'peak-rpm'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1d19ad7bef0&gt;
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_72_1.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_72_1.png"> --></p>

<p>Peak rpm does not seem like a good predictor of the price at all since the regression line is close to horizontal. Also, the data points are very scattered and far from the fitted line, showing lots of variability. Therefore it’s it is not a reliable variable.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># examine the correlation between 'peak-rpm' and 'price 
</span><span class="n">df</span><span class="p">[[</span><span class="s">'peak-rpm'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>peak-rpm</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>peak-rpm</th>
      <td>1.000000</td>
      <td>-0.101616</td>
    </tr>
    <tr>
      <th>price</th>
      <td>-0.101616</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="categorical-variables">
<a class="anchor" href="#categorical-variables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Categorical variables</h3>
<p>These are variables that describe a ‘characteristic’ of a data unit, and are selected from a small group of categories. The categorical variables can have the type “object” or “int64”. A good way to visualize categorical variables is by using boxplots.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># relationship between body-style and price
</span><span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'body-style'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1d19bfe7c88&gt;
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_76_1.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_76_1.png"> --></p>

<p>We see that the distributions of price between the different body-style categories have a significant overlap, and so body-style would not be a good predictor of price.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># relationship between engine location and price
</span><span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'engine-location'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1d19c0b2320&gt;
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_78_1.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_78_1.png"> --></p>

<p>We see that the distribution of price between these two engine-location categories, front and rear, are distinct enough to take engine-location as a potential good predictor of price.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># relationship etween drive wheels and price
</span><span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'drive-wheels'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1d19c125f98&gt;
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_80_1.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_80_1.png"> --></p>

<p>We see that the distribution of price between the different drive-wheels categories differs; as such, drive-wheels could potentially be a predictor of price.</p>

<h3 id="descriptive-statistical-analysis">
<a class="anchor" href="#descriptive-statistical-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Descriptive Statistical Analysis</h3>
<p>The <strong>describe</strong> function automatically computes basic statistics for all continuous variables. Any NaN values are automatically skipped in these statistics.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized-losses</th>
      <th>wheel-base</th>
      <th>length</th>
      <th>width</th>
      <th>height</th>
      <th>curb-weight</th>
      <th>engine-size</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression-ratio</th>
      <th>horsepower</th>
      <th>peak-rpm</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
      <th>price</th>
      <th>diesel</th>
      <th>gas</th>
      <th>aspiration-std</th>
      <th>aspiration-turbo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>201.000000</td>
      <td>201.00000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
      <td>201.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.840796</td>
      <td>122.00000</td>
      <td>98.797015</td>
      <td>0.837102</td>
      <td>0.915126</td>
      <td>0.899108</td>
      <td>2555.666667</td>
      <td>126.875622</td>
      <td>5.692289</td>
      <td>3.256874</td>
      <td>10.164279</td>
      <td>103.405534</td>
      <td>5117.665368</td>
      <td>25.179104</td>
      <td>30.686567</td>
      <td>13207.129353</td>
      <td>0.099502</td>
      <td>0.900498</td>
      <td>0.820896</td>
      <td>0.179104</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.254802</td>
      <td>31.99625</td>
      <td>6.066366</td>
      <td>0.059213</td>
      <td>0.029187</td>
      <td>0.040933</td>
      <td>517.296727</td>
      <td>41.546834</td>
      <td>16.616706</td>
      <td>0.316048</td>
      <td>4.004965</td>
      <td>37.365700</td>
      <td>478.113805</td>
      <td>6.423220</td>
      <td>6.815150</td>
      <td>7947.066342</td>
      <td>0.300083</td>
      <td>0.300083</td>
      <td>0.384397</td>
      <td>0.384397</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-2.000000</td>
      <td>65.00000</td>
      <td>86.600000</td>
      <td>0.678039</td>
      <td>0.837500</td>
      <td>0.799331</td>
      <td>1488.000000</td>
      <td>61.000000</td>
      <td>2.540000</td>
      <td>2.070000</td>
      <td>7.000000</td>
      <td>48.000000</td>
      <td>4150.000000</td>
      <td>13.000000</td>
      <td>16.000000</td>
      <td>5118.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>101.00000</td>
      <td>94.500000</td>
      <td>0.801538</td>
      <td>0.890278</td>
      <td>0.869565</td>
      <td>2169.000000</td>
      <td>98.000000</td>
      <td>3.150000</td>
      <td>3.110000</td>
      <td>8.600000</td>
      <td>70.000000</td>
      <td>4800.000000</td>
      <td>19.000000</td>
      <td>25.000000</td>
      <td>7775.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>122.00000</td>
      <td>97.000000</td>
      <td>0.832292</td>
      <td>0.909722</td>
      <td>0.904682</td>
      <td>2414.000000</td>
      <td>120.000000</td>
      <td>3.310000</td>
      <td>3.290000</td>
      <td>9.000000</td>
      <td>95.000000</td>
      <td>5125.369458</td>
      <td>24.000000</td>
      <td>30.000000</td>
      <td>10295.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.000000</td>
      <td>137.00000</td>
      <td>102.400000</td>
      <td>0.881788</td>
      <td>0.925000</td>
      <td>0.928094</td>
      <td>2926.000000</td>
      <td>141.000000</td>
      <td>3.600000</td>
      <td>3.410000</td>
      <td>9.400000</td>
      <td>116.000000</td>
      <td>5500.000000</td>
      <td>30.000000</td>
      <td>34.000000</td>
      <td>16500.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.000000</td>
      <td>256.00000</td>
      <td>120.900000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4066.000000</td>
      <td>326.000000</td>
      <td>122.000000</td>
      <td>4.170000</td>
      <td>23.000000</td>
      <td>262.000000</td>
      <td>6600.000000</td>
      <td>49.000000</td>
      <td>54.000000</td>
      <td>45400.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s">'object'</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>make</th>
      <th>num-of-doors</th>
      <th>body-style</th>
      <th>drive-wheels</th>
      <th>engine-location</th>
      <th>engine-type</th>
      <th>num-of-cylinders</th>
      <th>fuel-system</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>201</td>
      <td>201</td>
      <td>201</td>
      <td>201</td>
      <td>201</td>
      <td>201</td>
      <td>201</td>
      <td>201</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>22</td>
      <td>2</td>
      <td>5</td>
      <td>3</td>
      <td>2</td>
      <td>6</td>
      <td>7</td>
      <td>8</td>
    </tr>
    <tr>
      <th>top</th>
      <td>toyota</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>ohc</td>
      <td>four</td>
      <td>mpfi</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>32</td>
      <td>115</td>
      <td>94</td>
      <td>118</td>
      <td>198</td>
      <td>145</td>
      <td>157</td>
      <td>92</td>
    </tr>
  </tbody>
</table>
</div>

<p><strong>value_counts</strong> is a good way of understanding how many units of each characteristic/variable we have. The method “value_counts” only works on Pandas series, not Pandas Dataframes. As a result, we only include one bracket “df[‘drive-wheels’]” not two brackets “df[[‘drive-wheels’]]”.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'drive-wheels'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fwd    118
rwd     75
4wd      8
Name: drive-wheels, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the series to a dataframe
</span><span class="n">df</span><span class="p">[</span><span class="s">'drive-wheels'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">to_frame</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>drive-wheels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fwd</th>
      <td>118</td>
    </tr>
    <tr>
      <th>rwd</th>
      <td>75</td>
    </tr>
    <tr>
      <th>4wd</th>
      <td>8</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># rename the column 'drive-wheels' to 'value_counts'
</span><span class="n">drive_wheels_counts</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'drive-wheels'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">drive_wheels_counts</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'drive-wheels'</span><span class="p">:</span> <span class="s">'value_counts'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">drive_wheels_counts</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>value_counts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fwd</th>
      <td>118</td>
    </tr>
    <tr>
      <th>rwd</th>
      <td>75</td>
    </tr>
    <tr>
      <th>4wd</th>
      <td>8</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># rename the index to 'drive-wheels'
</span><span class="n">drive_wheels_counts</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="s">'drive-wheels'</span>
<span class="n">drive_wheels_counts</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>value_counts</th>
    </tr>
    <tr>
      <th>drive-wheels</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fwd</th>
      <td>118</td>
    </tr>
    <tr>
      <th>rwd</th>
      <td>75</td>
    </tr>
    <tr>
      <th>4wd</th>
      <td>8</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># value_counts for engine location
</span><span class="n">engine_loc_counts</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'engine-location'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">engine_loc_counts</span><span class="p">.</span><span class="n">rename</span><span class="p">({</span><span class="s">'engine-location'</span><span class="p">:</span> <span class="s">'value_counts'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">engine_loc_counts</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="s">'engine-location'</span>
<span class="n">engine_loc_counts</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>engine-location</th>
    </tr>
    <tr>
      <th>engine-location</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>front</th>
      <td>198</td>
    </tr>
    <tr>
      <th>rear</th>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>

<p>The value counts of the engine location would not be a good predictor variable for the price. This is because we only have 3 cars with a rear engine and 198 with an engine in the front; this result is skewed. Thus, we are not able to draw any conclusions about the engine location.</p>

<h3 id="grouping">
<a class="anchor" href="#grouping" aria-hidden="true"><span class="octicon octicon-link"></span></a>Grouping</h3>
<p>The ‘groupby’ method groups data by different categories. The data is grouped based on one or several variables and analysis is performed on the individual groups.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># categories of drive wheels
</span><span class="n">df</span><span class="p">[</span><span class="s">'drive-wheels'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['rwd', 'fwd', '4wd'], dtype=object)
</code></pre></div></div>

<p>If we want to know on average, which type of drive wheel is most valuable, we can group ‘drive-wheels’ and then average them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># select columns and assign them to a variable
</span><span class="n">df_group_one</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'drive-wheels'</span><span class="p">,</span> <span class="s">'body-style'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">]]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># grouping
# calculate the average price for each of the different categories of data
</span><span class="n">df_group_one</span> <span class="o">=</span> <span class="n">df_group_one</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'drive-wheels'</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
<span class="n">df_group_one</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>drive-wheels</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4wd</td>
      <td>10241.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fwd</td>
      <td>9244.779661</td>
    </tr>
    <tr>
      <th>2</th>
      <td>rwd</td>
      <td>19757.613333</td>
    </tr>
  </tbody>
</table>
</div>

<p>It seems that rear-wheel drive vehicles are, on average, the most expensive, while 4-wheel drive and front-wheel drive are approximately the same price.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># grouping with multiple variables
</span><span class="n">df_gptest</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'drive-wheels'</span><span class="p">,</span> <span class="s">'body-style'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">]]</span>
<span class="n">grouped_test1</span> <span class="o">=</span> <span class="n">df_gptest</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'drive-wheels'</span><span class="p">,</span> <span class="s">'body-style'</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
<span class="n">grouped_test1</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>drive-wheels</th>
      <th>body-style</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4wd</td>
      <td>hatchback</td>
      <td>7603.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4wd</td>
      <td>sedan</td>
      <td>12647.333333</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4wd</td>
      <td>wagon</td>
      <td>9095.750000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fwd</td>
      <td>convertible</td>
      <td>11595.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>fwd</td>
      <td>hardtop</td>
      <td>8249.000000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>fwd</td>
      <td>hatchback</td>
      <td>8396.387755</td>
    </tr>
    <tr>
      <th>6</th>
      <td>fwd</td>
      <td>sedan</td>
      <td>9811.800000</td>
    </tr>
    <tr>
      <th>7</th>
      <td>fwd</td>
      <td>wagon</td>
      <td>9997.333333</td>
    </tr>
    <tr>
      <th>8</th>
      <td>rwd</td>
      <td>convertible</td>
      <td>23949.600000</td>
    </tr>
    <tr>
      <th>9</th>
      <td>rwd</td>
      <td>hardtop</td>
      <td>24202.714286</td>
    </tr>
    <tr>
      <th>10</th>
      <td>rwd</td>
      <td>hatchback</td>
      <td>14337.777778</td>
    </tr>
    <tr>
      <th>11</th>
      <td>rwd</td>
      <td>sedan</td>
      <td>21711.833333</td>
    </tr>
    <tr>
      <th>12</th>
      <td>rwd</td>
      <td>wagon</td>
      <td>16994.222222</td>
    </tr>
  </tbody>
</table>
</div>

<p>This grouped data is much easier to visualize when it is made into a pivot table. A pivot table is like an Excel spreadsheet, with one variable along the column and another along the row. We can convert the dataframe to a pivot table using the method ‘pivot’ to create a pivot table from the groups.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># leave the drive-wheel variable as the rows and pivot body-style to become the columns of the table
</span><span class="n">grouped_pivot</span> <span class="o">=</span> <span class="n">grouped_test1</span><span class="p">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s">'drive-wheels'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s">'body-style'</span><span class="p">)</span>
<span class="n">grouped_pivot</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="5" halign="left">price</th>
    </tr>
    <tr>
      <th>body-style</th>
      <th>convertible</th>
      <th>hardtop</th>
      <th>hatchback</th>
      <th>sedan</th>
      <th>wagon</th>
    </tr>
    <tr>
      <th>drive-wheels</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4wd</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>7603.000000</td>
      <td>12647.333333</td>
      <td>9095.750000</td>
    </tr>
    <tr>
      <th>fwd</th>
      <td>11595.0</td>
      <td>8249.000000</td>
      <td>8396.387755</td>
      <td>9811.800000</td>
      <td>9997.333333</td>
    </tr>
    <tr>
      <th>rwd</th>
      <td>23949.6</td>
      <td>24202.714286</td>
      <td>14337.777778</td>
      <td>21711.833333</td>
      <td>16994.222222</td>
    </tr>
  </tbody>
</table>
</div>

<p>Often, we won’t have data for some of the pivot cells. We can fill these missing cells with the value 0, but any other value could potentially be used as well.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># fill missing values with 0
</span><span class="n">grouped_pivot</span> <span class="o">=</span> <span class="n">grouped_pivot</span><span class="p">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> 
<span class="n">grouped_pivot</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="5" halign="left">price</th>
    </tr>
    <tr>
      <th>body-style</th>
      <th>convertible</th>
      <th>hardtop</th>
      <th>hatchback</th>
      <th>sedan</th>
      <th>wagon</th>
    </tr>
    <tr>
      <th>drive-wheels</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4wd</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>7603.000000</td>
      <td>12647.333333</td>
      <td>9095.750000</td>
    </tr>
    <tr>
      <th>fwd</th>
      <td>11595.0</td>
      <td>8249.000000</td>
      <td>8396.387755</td>
      <td>9811.800000</td>
      <td>9997.333333</td>
    </tr>
    <tr>
      <th>rwd</th>
      <td>23949.6</td>
      <td>24202.714286</td>
      <td>14337.777778</td>
      <td>21711.833333</td>
      <td>16994.222222</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># groupby to find  average price of each car based on body style
</span><span class="n">df_gptest_2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'body-style'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">]]</span>
<span class="n">grouped_test_bodystyle</span> <span class="o">=</span> <span class="n">df_gptest_2</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'body-style'</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
<span class="n">grouped_test_bodystyle</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>body-style</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>convertible</td>
      <td>21890.500000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>hardtop</td>
      <td>22208.500000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hatchback</td>
      <td>9957.441176</td>
    </tr>
    <tr>
      <th>3</th>
      <td>sedan</td>
      <td>14459.755319</td>
    </tr>
    <tr>
      <th>4</th>
      <td>wagon</td>
      <td>12371.960000</td>
    </tr>
  </tbody>
</table>
</div>

<p>Use a heat map to visualize the relationship between Body Style vs Price</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use the grouped results
</span><span class="n">plt</span><span class="p">.</span><span class="n">pcolor</span><span class="p">(</span><span class="n">grouped_pivot</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'RdBu'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_105_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_105_0.png"> --></p>

<p>The heatmap plots the target variable (price) proportional to colour with respect to the variables ‘drive-wheel’ and ‘body-style’ in the vertical and horizontal axis respectively. This allows us to visualize how the price is related to ‘drive-wheel’ and ‘body-style’.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">pcolor</span><span class="p">(</span><span class="n">grouped_pivot</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'RdBu'</span><span class="p">)</span>

<span class="c1">#label names
</span><span class="n">row_labels</span> <span class="o">=</span> <span class="n">grouped_pivot</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="n">levels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">col_labels</span> <span class="o">=</span> <span class="n">grouped_pivot</span><span class="p">.</span><span class="n">index</span>

<span class="c1">#move ticks and labels to the center
</span><span class="n">ax</span><span class="p">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">grouped_pivot</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">grouped_pivot</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">#insert labels
</span><span class="n">ax</span><span class="p">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">row_labels</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">col_labels</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">#rotate label if too long
</span><span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_107_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_107_0.png"> --></p>

<h3 id="correlation-and-causation">
<a class="anchor" href="#correlation-and-causation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Correlation and Causation</h3>
<p><strong>Correlation</strong>: a measure of the extent of interdependence between variables.</p>

<p><strong>Causation</strong>: the relationship between cause and effect between two variables.</p>

<p>Correlation doesn’t imply causation.</p>

<p>Persaon Correlation: It measures the linear dependence between two variables X and Y.</p>

<p>The resulting coefficient is a value between -1 and 1 inclusive, where:</p>

<ul>
  <li>1: Total positive linear correlation.</li>
  <li>0: No linear correlation, the two variables most likely do not affect each other.</li>
  <li>-1: Total negative linear correlation</li>
</ul>

<p>Pearson Correlation is the default method of the function “corr”. Like before we can calculate the Pearson Correlation of the ‘int64’ or ‘float64’ variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calculate the Pearson coefficient
</span><span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized-losses</th>
      <th>wheel-base</th>
      <th>length</th>
      <th>width</th>
      <th>height</th>
      <th>curb-weight</th>
      <th>engine-size</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression-ratio</th>
      <th>horsepower</th>
      <th>peak-rpm</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
      <th>price</th>
      <th>diesel</th>
      <th>gas</th>
      <th>aspiration-std</th>
      <th>aspiration-turbo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>symboling</th>
      <td>1.000000</td>
      <td>0.466264</td>
      <td>-0.535987</td>
      <td>-0.365404</td>
      <td>-0.242423</td>
      <td>-0.550160</td>
      <td>-0.233118</td>
      <td>-0.110581</td>
      <td>0.243521</td>
      <td>-0.008153</td>
      <td>-0.182196</td>
      <td>0.075819</td>
      <td>0.279740</td>
      <td>-0.035527</td>
      <td>0.036233</td>
      <td>-0.082391</td>
      <td>-0.196735</td>
      <td>0.196735</td>
      <td>0.054615</td>
      <td>-0.054615</td>
    </tr>
    <tr>
      <th>normalized-losses</th>
      <td>0.466264</td>
      <td>1.000000</td>
      <td>-0.056661</td>
      <td>0.019424</td>
      <td>0.086802</td>
      <td>-0.373737</td>
      <td>0.099404</td>
      <td>0.112360</td>
      <td>0.124511</td>
      <td>0.055045</td>
      <td>-0.114713</td>
      <td>0.217299</td>
      <td>0.239543</td>
      <td>-0.225016</td>
      <td>-0.181877</td>
      <td>0.133999</td>
      <td>-0.101546</td>
      <td>0.101546</td>
      <td>0.006911</td>
      <td>-0.006911</td>
    </tr>
    <tr>
      <th>wheel-base</th>
      <td>-0.535987</td>
      <td>-0.056661</td>
      <td>1.000000</td>
      <td>0.876024</td>
      <td>0.814507</td>
      <td>0.590742</td>
      <td>0.782097</td>
      <td>0.572027</td>
      <td>-0.074380</td>
      <td>0.158018</td>
      <td>0.250313</td>
      <td>0.371147</td>
      <td>-0.360305</td>
      <td>-0.470606</td>
      <td>-0.543304</td>
      <td>0.584642</td>
      <td>0.307237</td>
      <td>-0.307237</td>
      <td>-0.256889</td>
      <td>0.256889</td>
    </tr>
    <tr>
      <th>length</th>
      <td>-0.365404</td>
      <td>0.019424</td>
      <td>0.876024</td>
      <td>1.000000</td>
      <td>0.857170</td>
      <td>0.492063</td>
      <td>0.880665</td>
      <td>0.685025</td>
      <td>-0.050463</td>
      <td>0.123952</td>
      <td>0.159733</td>
      <td>0.579821</td>
      <td>-0.285970</td>
      <td>-0.665192</td>
      <td>-0.698142</td>
      <td>0.690628</td>
      <td>0.211187</td>
      <td>-0.211187</td>
      <td>-0.230085</td>
      <td>0.230085</td>
    </tr>
    <tr>
      <th>width</th>
      <td>-0.242423</td>
      <td>0.086802</td>
      <td>0.814507</td>
      <td>0.857170</td>
      <td>1.000000</td>
      <td>0.306002</td>
      <td>0.866201</td>
      <td>0.729436</td>
      <td>-0.004059</td>
      <td>0.188822</td>
      <td>0.189867</td>
      <td>0.615077</td>
      <td>-0.245800</td>
      <td>-0.633531</td>
      <td>-0.680635</td>
      <td>0.751265</td>
      <td>0.244356</td>
      <td>-0.244356</td>
      <td>-0.305732</td>
      <td>0.305732</td>
    </tr>
    <tr>
      <th>height</th>
      <td>-0.550160</td>
      <td>-0.373737</td>
      <td>0.590742</td>
      <td>0.492063</td>
      <td>0.306002</td>
      <td>1.000000</td>
      <td>0.307581</td>
      <td>0.074694</td>
      <td>-0.240217</td>
      <td>-0.060663</td>
      <td>0.259737</td>
      <td>-0.087027</td>
      <td>-0.309974</td>
      <td>-0.049800</td>
      <td>-0.104812</td>
      <td>0.135486</td>
      <td>0.281578</td>
      <td>-0.281578</td>
      <td>-0.090336</td>
      <td>0.090336</td>
    </tr>
    <tr>
      <th>curb-weight</th>
      <td>-0.233118</td>
      <td>0.099404</td>
      <td>0.782097</td>
      <td>0.880665</td>
      <td>0.866201</td>
      <td>0.307581</td>
      <td>1.000000</td>
      <td>0.849072</td>
      <td>-0.029485</td>
      <td>0.167438</td>
      <td>0.156433</td>
      <td>0.757976</td>
      <td>-0.279361</td>
      <td>-0.749543</td>
      <td>-0.794889</td>
      <td>0.834415</td>
      <td>0.221046</td>
      <td>-0.221046</td>
      <td>-0.321955</td>
      <td>0.321955</td>
    </tr>
    <tr>
      <th>engine-size</th>
      <td>-0.110581</td>
      <td>0.112360</td>
      <td>0.572027</td>
      <td>0.685025</td>
      <td>0.729436</td>
      <td>0.074694</td>
      <td>0.849072</td>
      <td>1.000000</td>
      <td>-0.177698</td>
      <td>0.205928</td>
      <td>0.028889</td>
      <td>0.822676</td>
      <td>-0.256733</td>
      <td>-0.650546</td>
      <td>-0.679571</td>
      <td>0.872335</td>
      <td>0.070779</td>
      <td>-0.070779</td>
      <td>-0.110040</td>
      <td>0.110040</td>
    </tr>
    <tr>
      <th>bore</th>
      <td>0.243521</td>
      <td>0.124511</td>
      <td>-0.074380</td>
      <td>-0.050463</td>
      <td>-0.004059</td>
      <td>-0.240217</td>
      <td>-0.029485</td>
      <td>-0.177698</td>
      <td>1.000000</td>
      <td>-0.001549</td>
      <td>-0.027237</td>
      <td>0.032443</td>
      <td>0.259276</td>
      <td>-0.196827</td>
      <td>-0.170635</td>
      <td>0.005399</td>
      <td>-0.046482</td>
      <td>0.046482</td>
      <td>0.062876</td>
      <td>-0.062876</td>
    </tr>
    <tr>
      <th>stroke</th>
      <td>-0.008153</td>
      <td>0.055045</td>
      <td>0.158018</td>
      <td>0.123952</td>
      <td>0.188822</td>
      <td>-0.060663</td>
      <td>0.167438</td>
      <td>0.205928</td>
      <td>-0.001549</td>
      <td>1.000000</td>
      <td>0.187871</td>
      <td>0.098267</td>
      <td>-0.063561</td>
      <td>-0.033956</td>
      <td>-0.034636</td>
      <td>0.082269</td>
      <td>0.241064</td>
      <td>-0.241064</td>
      <td>-0.218233</td>
      <td>0.218233</td>
    </tr>
    <tr>
      <th>compression-ratio</th>
      <td>-0.182196</td>
      <td>-0.114713</td>
      <td>0.250313</td>
      <td>0.159733</td>
      <td>0.189867</td>
      <td>0.259737</td>
      <td>0.156433</td>
      <td>0.028889</td>
      <td>-0.027237</td>
      <td>0.187871</td>
      <td>1.000000</td>
      <td>-0.214514</td>
      <td>-0.435780</td>
      <td>0.331425</td>
      <td>0.268465</td>
      <td>0.071107</td>
      <td>0.985231</td>
      <td>-0.985231</td>
      <td>-0.307522</td>
      <td>0.307522</td>
    </tr>
    <tr>
      <th>horsepower</th>
      <td>0.075819</td>
      <td>0.217299</td>
      <td>0.371147</td>
      <td>0.579821</td>
      <td>0.615077</td>
      <td>-0.087027</td>
      <td>0.757976</td>
      <td>0.822676</td>
      <td>0.032443</td>
      <td>0.098267</td>
      <td>-0.214514</td>
      <td>1.000000</td>
      <td>0.107885</td>
      <td>-0.822214</td>
      <td>-0.804575</td>
      <td>0.809575</td>
      <td>-0.169053</td>
      <td>0.169053</td>
      <td>-0.251127</td>
      <td>0.251127</td>
    </tr>
    <tr>
      <th>peak-rpm</th>
      <td>0.279740</td>
      <td>0.239543</td>
      <td>-0.360305</td>
      <td>-0.285970</td>
      <td>-0.245800</td>
      <td>-0.309974</td>
      <td>-0.279361</td>
      <td>-0.256733</td>
      <td>0.259276</td>
      <td>-0.063561</td>
      <td>-0.435780</td>
      <td>0.107885</td>
      <td>1.000000</td>
      <td>-0.115413</td>
      <td>-0.058598</td>
      <td>-0.101616</td>
      <td>-0.475812</td>
      <td>0.475812</td>
      <td>0.190057</td>
      <td>-0.190057</td>
    </tr>
    <tr>
      <th>city-mpg</th>
      <td>-0.035527</td>
      <td>-0.225016</td>
      <td>-0.470606</td>
      <td>-0.665192</td>
      <td>-0.633531</td>
      <td>-0.049800</td>
      <td>-0.749543</td>
      <td>-0.650546</td>
      <td>-0.196827</td>
      <td>-0.033956</td>
      <td>0.331425</td>
      <td>-0.822214</td>
      <td>-0.115413</td>
      <td>1.000000</td>
      <td>0.972044</td>
      <td>-0.686571</td>
      <td>0.265676</td>
      <td>-0.265676</td>
      <td>0.189237</td>
      <td>-0.189237</td>
    </tr>
    <tr>
      <th>highway-mpg</th>
      <td>0.036233</td>
      <td>-0.181877</td>
      <td>-0.543304</td>
      <td>-0.698142</td>
      <td>-0.680635</td>
      <td>-0.104812</td>
      <td>-0.794889</td>
      <td>-0.679571</td>
      <td>-0.170635</td>
      <td>-0.034636</td>
      <td>0.268465</td>
      <td>-0.804575</td>
      <td>-0.058598</td>
      <td>0.972044</td>
      <td>1.000000</td>
      <td>-0.704692</td>
      <td>0.198690</td>
      <td>-0.198690</td>
      <td>0.241851</td>
      <td>-0.241851</td>
    </tr>
    <tr>
      <th>price</th>
      <td>-0.082391</td>
      <td>0.133999</td>
      <td>0.584642</td>
      <td>0.690628</td>
      <td>0.751265</td>
      <td>0.135486</td>
      <td>0.834415</td>
      <td>0.872335</td>
      <td>0.005399</td>
      <td>0.082269</td>
      <td>0.071107</td>
      <td>0.809575</td>
      <td>-0.101616</td>
      <td>-0.686571</td>
      <td>-0.704692</td>
      <td>1.000000</td>
      <td>0.110326</td>
      <td>-0.110326</td>
      <td>-0.179578</td>
      <td>0.179578</td>
    </tr>
    <tr>
      <th>diesel</th>
      <td>-0.196735</td>
      <td>-0.101546</td>
      <td>0.307237</td>
      <td>0.211187</td>
      <td>0.244356</td>
      <td>0.281578</td>
      <td>0.221046</td>
      <td>0.070779</td>
      <td>-0.046482</td>
      <td>0.241064</td>
      <td>0.985231</td>
      <td>-0.169053</td>
      <td>-0.475812</td>
      <td>0.265676</td>
      <td>0.198690</td>
      <td>0.110326</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>-0.408228</td>
      <td>0.408228</td>
    </tr>
    <tr>
      <th>gas</th>
      <td>0.196735</td>
      <td>0.101546</td>
      <td>-0.307237</td>
      <td>-0.211187</td>
      <td>-0.244356</td>
      <td>-0.281578</td>
      <td>-0.221046</td>
      <td>-0.070779</td>
      <td>0.046482</td>
      <td>-0.241064</td>
      <td>-0.985231</td>
      <td>0.169053</td>
      <td>0.475812</td>
      <td>-0.265676</td>
      <td>-0.198690</td>
      <td>-0.110326</td>
      <td>-1.000000</td>
      <td>1.000000</td>
      <td>0.408228</td>
      <td>-0.408228</td>
    </tr>
    <tr>
      <th>aspiration-std</th>
      <td>0.054615</td>
      <td>0.006911</td>
      <td>-0.256889</td>
      <td>-0.230085</td>
      <td>-0.305732</td>
      <td>-0.090336</td>
      <td>-0.321955</td>
      <td>-0.110040</td>
      <td>0.062876</td>
      <td>-0.218233</td>
      <td>-0.307522</td>
      <td>-0.251127</td>
      <td>0.190057</td>
      <td>0.189237</td>
      <td>0.241851</td>
      <td>-0.179578</td>
      <td>-0.408228</td>
      <td>0.408228</td>
      <td>1.000000</td>
      <td>-1.000000</td>
    </tr>
    <tr>
      <th>aspiration-turbo</th>
      <td>-0.054615</td>
      <td>-0.006911</td>
      <td>0.256889</td>
      <td>0.230085</td>
      <td>0.305732</td>
      <td>0.090336</td>
      <td>0.321955</td>
      <td>0.110040</td>
      <td>-0.062876</td>
      <td>0.218233</td>
      <td>0.307522</td>
      <td>0.251127</td>
      <td>-0.190057</td>
      <td>-0.189237</td>
      <td>-0.241851</td>
      <td>0.179578</td>
      <td>0.408228</td>
      <td>-0.408228</td>
      <td>-1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([111.        , 154.        , 102.        , 115.        ,
       110.        , 140.        , 101.        , 121.        ,
       182.        ,  48.        ,  70.        ,  68.        ,
        88.        , 145.        ,  58.        ,  76.        ,
        60.        ,  86.        , 100.        ,  78.        ,
        90.        , 176.        , 262.        , 135.        ,
        84.        ,  64.        , 120.        ,  72.        ,
       123.        , 155.        , 184.        , 175.        ,
       116.        ,  69.        ,  55.        ,  97.        ,
       152.        , 160.        , 200.        ,  95.        ,
       142.        , 143.        , 207.        , 104.25615764,
        73.        ,  82.        ,  94.        ,  62.        ,
        56.        , 112.        ,  92.        , 161.        ,
       156.        ,  52.        ,  85.        , 114.        ,
       162.        , 134.        , 106.        ])
</code></pre></div></div>

<p>To know the significance of the correlation estimate, we calculate the P-value.<br>
The P-value is the probability value that the correlation between these two variables is statistically significant. Normally, we choose a significance level of 0.05, which means that we are 95% confident that the correlation between the variables is significant.</p>

<p>By convention, when the</p>
<ul>
  <li>p-value is &lt; 0.001: we say there is strong evidence that the correlation is significant.</li>
  <li>p-value is &lt; 0.05: there is moderate evidence that the correlation is significant.</li>
  <li>p-value is &lt; 0.1: there is weak evidence that the correlation is significant.</li>
  <li>p-value is &gt; 0.1: there is no evidence that the correlation is significant.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte the Pearson coefficient and p-value of wheel base and price
</span><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'wheel-base'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Pearson Correlation Coefficient is '</span><span class="p">,</span> <span class="n">pearson_coef</span><span class="p">,</span> <span class="s">' with a P-value of P='</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The Pearson Correlation Coefficient is  0.5846418222655081  with a P-value of P= 8.076488270732989e-20
</code></pre></div></div>

<p>Since the p-value is &lt; 0.001, the correlation between wheel-base and price is statistically significant, although the linear relationship isn’t extremely strong (~0.585)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte the Pearson coefficient and p-value of horsepower and price
</span><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Pearson Correlation Coefficient is '</span><span class="p">,</span> <span class="n">pearson_coef</span><span class="p">,</span> <span class="s">' with a P-value of P='</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The Pearson Correlation Coefficient is  0.809574567003656  with a P-value of P= 6.369057428259557e-48
</code></pre></div></div>

<p>Since the p-value is &lt; 0.001, the correlation between horsepower and price is statistically significant, and the linear relationship is quite strong (~0.809, close to 1)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte the Pearson coefficient and p-value of length and price
</span><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'length'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Pearson Correlation Coefficient is '</span><span class="p">,</span> <span class="n">pearson_coef</span><span class="p">,</span> <span class="s">' with a P-value of P='</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The Pearson Correlation Coefficient is  0.6906283804483642  with a P-value of P= 8.016477466158759e-30
</code></pre></div></div>

<p>Since the p-value is &lt; 0.001, the correlation between length and price is statistically significant, and the linear relationship is moderately strong (~0.691).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte the Pearson coefficient and p-value of width and price
</span><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'width'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Pearson Correlation Coefficient is '</span><span class="p">,</span> <span class="n">pearson_coef</span><span class="p">,</span> <span class="s">' with a P-value of P='</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The Pearson Correlation Coefficient is  0.7512653440522673  with a P-value of P= 9.200335510481646e-38
</code></pre></div></div>

<p>Since the p-value is &lt; 0.001, the correlation between width and price is statistically significant, and the linear relationship is quite strong (~0.751).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte the Pearson coefficient and p-value of curb weight and price
</span><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'curb-weight'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Pearson Correlation Coefficient is '</span><span class="p">,</span> <span class="n">pearson_coef</span><span class="p">,</span> <span class="s">' with a P-value of P='</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The Pearson Correlation Coefficient is  0.8344145257702846  with a P-value of P= 2.1895772388936914e-53
</code></pre></div></div>

<p>Since the p-value is &lt; 0.001, the correlation between curb-weight and price is statistically significant, and the linear relationship is quite strong (~0.834).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte the Pearson coefficient and p-value of engine size and price
</span><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'engine-size'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Pearson Correlation Coefficient is '</span><span class="p">,</span> <span class="n">pearson_coef</span><span class="p">,</span> <span class="s">' with a P-value of P='</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The Pearson Correlation Coefficient is  0.8723351674455185  with a P-value of P= 9.265491622198389e-64
</code></pre></div></div>

<p>Since the p-value is &lt; 0.001, the correlation between engine-size and price is statistically significant, and the linear relationship is very strong (~0.872).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte the Pearson coefficient and p-value of bore and price
</span><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'bore'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Pearson Correlation Coefficient is '</span><span class="p">,</span> <span class="n">pearson_coef</span><span class="p">,</span> <span class="s">' with a P-value of P='</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The Pearson Correlation Coefficient is  0.005399275177997414  with a P-value of P= 0.9393625495207799
</code></pre></div></div>

<p>Since the p-value is &lt; 0.001, the correlation between bore and price is statistically significant, but the linear relationship is only moderate (~0.521).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte the Pearson coefficient and p-value of city-mpg and price
</span><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'city-mpg'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Pearson Correlation Coefficient is '</span><span class="p">,</span> <span class="n">pearson_coef</span><span class="p">,</span> <span class="s">' with a P-value of P='</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The Pearson Correlation Coefficient is  -0.6865710067844677  with a P-value of P= 2.321132065567674e-29
</code></pre></div></div>

<p>Since the p-value is &lt; 0.001, the correlation between city-mpg and price is statistically significant, and the coefficient of ~ -0.687 shows that the relationship is negative and moderately strong.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte the Pearson coefficient and p-value of highway-mpg and price
</span><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'highway-mpg'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Pearson Correlation Coefficient is '</span><span class="p">,</span> <span class="n">pearson_coef</span><span class="p">,</span> <span class="s">' with a P-value of P='</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The Pearson Correlation Coefficient is  -0.7046922650589529  with a P-value of P= 1.7495471144477352e-31
</code></pre></div></div>

<p>Since the p-value is &lt; 0.001, the correlation between highway-mpg and price is statistically significant, and the coefficient of ~ -0.705 shows that the relationship is negative and moderately strong.</p>

<h3 id="anova-analyis-of-variance">
<a class="anchor" href="#anova-analyis-of-variance" aria-hidden="true"><span class="octicon octicon-link"></span></a>ANOVA (Analyis of Variance)</h3>
<p>The Analysis of Variance (ANOVA) is a statistical method used to test whether there are significant differences between the means of two or more groups. ANOVA returns two parameters:</p>

<p><strong>F-test score</strong>: ANOVA assumes the means of all groups are the same, calculates how much the actual means deviate from the assumption, and reports it as the F-test score. A larger score means there is a larger difference between the means.</p>

<p><strong>P-value</strong>: P-value tells how statistically significant is our calculated score value.</p>

<p>If our price variable is strongly correlated with the variable we are analyzing, expect ANOVA to return a sizeable F-test score and a small p-value.</p>

<p>Since ANOVA analyzes the difference between different groups of the same variable, the groupby function will come in handy. Because the ANOVA algorithm averages the data automatically, we do not need to take the average before hand.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># check if different types of drive wheels impact price
# group the data
</span><span class="n">grouped_test2</span> <span class="o">=</span> <span class="n">df_gptest</span><span class="p">[[</span><span class="s">'drive-wheels'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">]].</span><span class="n">groupby</span><span class="p">([</span><span class="s">'drive-wheels'</span><span class="p">])</span>
<span class="n">grouped_test2</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>drive-wheels</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>rwd</td>
      <td>13495.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>rwd</td>
      <td>16500.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fwd</td>
      <td>13950.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4wd</td>
      <td>17450.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>fwd</td>
      <td>15250.0</td>
    </tr>
    <tr>
      <th>136</th>
      <td>4wd</td>
      <td>7603.0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_gptest</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>drive-wheels</th>
      <th>body-style</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>rwd</td>
      <td>convertible</td>
      <td>13495.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>rwd</td>
      <td>convertible</td>
      <td>16500.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>rwd</td>
      <td>hatchback</td>
      <td>16500.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fwd</td>
      <td>sedan</td>
      <td>13950.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4wd</td>
      <td>sedan</td>
      <td>17450.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>196</th>
      <td>rwd</td>
      <td>sedan</td>
      <td>16845.0</td>
    </tr>
    <tr>
      <th>197</th>
      <td>rwd</td>
      <td>sedan</td>
      <td>19045.0</td>
    </tr>
    <tr>
      <th>198</th>
      <td>rwd</td>
      <td>sedan</td>
      <td>21485.0</td>
    </tr>
    <tr>
      <th>199</th>
      <td>rwd</td>
      <td>sedan</td>
      <td>22470.0</td>
    </tr>
    <tr>
      <th>200</th>
      <td>rwd</td>
      <td>sedan</td>
      <td>22625.0</td>
    </tr>
  </tbody>
</table>
<p>201 rows × 3 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># obtain the values of the method group using the method "get_group"
</span><span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'4wd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4      17450.0
136     7603.0
140     9233.0
141    11259.0
144     8013.0
145    11694.0
150     7898.0
151     8778.0
Name: price, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ANOVA
</span><span class="n">f_val</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">f_oneway</span><span class="p">(</span><span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'fwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'rwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'4wd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"ANOVA results: F="</span><span class="p">,</span> <span class="n">f_val</span><span class="p">,</span> <span class="s">", P ="</span><span class="p">,</span> <span class="n">p_val</span><span class="p">)</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ANOVA results: F= 67.95406500780399 , P = 3.3945443577151245e-23
</code></pre></div></div>

<p>This is a great result, with a large F test score showing a strong correlation and a P value of almost 0 implying almost certain statistical significance. But does this mean all three tested groups are all this highly correlated?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># separately fwd and rwd
</span><span class="n">f_val</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">f_oneway</span><span class="p">(</span><span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'fwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'rwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">])</span>  
<span class="k">print</span><span class="p">(</span> <span class="s">"ANOVA results: F="</span><span class="p">,</span> <span class="n">f_val</span><span class="p">,</span> <span class="s">", P ="</span><span class="p">,</span> <span class="n">p_val</span> <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ANOVA results: F= 130.5533160959111 , P = 2.2355306355677845e-23
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># separately 4wd and rwd
</span><span class="n">f_val</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">f_oneway</span><span class="p">(</span><span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'4wd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'rwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">])</span>  
<span class="k">print</span><span class="p">(</span> <span class="s">"ANOVA results: F="</span><span class="p">,</span> <span class="n">f_val</span><span class="p">,</span> <span class="s">", P ="</span><span class="p">,</span> <span class="n">p_val</span><span class="p">)</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ANOVA results: F= 8.580681368924756 , P = 0.004411492211225333
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># separately 4wd and fwd
</span><span class="n">f_val</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">f_oneway</span><span class="p">(</span><span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'4wd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'fwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">])</span>   
<span class="k">print</span><span class="p">(</span><span class="s">"ANOVA results: F="</span><span class="p">,</span> <span class="n">f_val</span><span class="p">,</span> <span class="s">", P ="</span><span class="p">,</span> <span class="n">p_val</span><span class="p">)</span>   
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ANOVA results: F= 0.665465750252303 , P = 0.41620116697845666
</code></pre></div></div>

<h4 id="conclusion-important-variables">
<a class="anchor" href="#conclusion-important-variables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion: Important Variables</h4>

<p>We now have a better idea of what our data looks like and which variables are important to take into account when predicting the car price. We have narrowed it down to the following variables:</p>

<p>Continuous numerical variables:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Length
Width
Curb-weight
Engine-size
Horsepower
City-mpg
Highway-mpg
Wheel-base
Bore
</code></pre></div></div>

<p>Categorical variables:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Drive-wheels
</code></pre></div></div>

<h2 id="model-development">
<a class="anchor" href="#model-development" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model Development</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># path of data 
</span><span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized-losses</th>
      <th>make</th>
      <th>num-of-doors</th>
      <th>body-style</th>
      <th>drive-wheels</th>
      <th>engine-location</th>
      <th>wheel-base</th>
      <th>length</th>
      <th>width</th>
      <th>...</th>
      <th>horsepower</th>
      <th>peak-rpm</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
      <th>price</th>
      <th>horsepower-binned</th>
      <th>diesel</th>
      <th>gas</th>
      <th>aspiration-std</th>
      <th>aspiration-turbo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>122</td>
      <td>alfa-romero</td>
      <td>two</td>
      <td>convertible</td>
      <td>rwd</td>
      <td>front</td>
      <td>88.6</td>
      <td>0.811148</td>
      <td>0.890278</td>
      <td>...</td>
      <td>111.0</td>
      <td>5000.0</td>
      <td>21</td>
      <td>27</td>
      <td>13495.0</td>
      <td>low</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>122</td>
      <td>alfa-romero</td>
      <td>two</td>
      <td>convertible</td>
      <td>rwd</td>
      <td>front</td>
      <td>88.6</td>
      <td>0.811148</td>
      <td>0.890278</td>
      <td>...</td>
      <td>111.0</td>
      <td>5000.0</td>
      <td>21</td>
      <td>27</td>
      <td>16500.0</td>
      <td>low</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>122</td>
      <td>alfa-romero</td>
      <td>two</td>
      <td>hatchback</td>
      <td>rwd</td>
      <td>front</td>
      <td>94.5</td>
      <td>0.822681</td>
      <td>0.909722</td>
      <td>...</td>
      <td>154.0</td>
      <td>5000.0</td>
      <td>19</td>
      <td>26</td>
      <td>16500.0</td>
      <td>medium</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>164</td>
      <td>audi</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>99.8</td>
      <td>0.848630</td>
      <td>0.919444</td>
      <td>...</td>
      <td>102.0</td>
      <td>5500.0</td>
      <td>24</td>
      <td>30</td>
      <td>13950.0</td>
      <td>low</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>164</td>
      <td>audi</td>
      <td>four</td>
      <td>sedan</td>
      <td>4wd</td>
      <td>front</td>
      <td>99.4</td>
      <td>0.848630</td>
      <td>0.922222</td>
      <td>...</td>
      <td>115.0</td>
      <td>5500.0</td>
      <td>18</td>
      <td>22</td>
      <td>17450.0</td>
      <td>low</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 29 columns</p>
</div>

<h3 id="linear-regression-and-multiple-linear-regression">
<a class="anchor" href="#linear-regression-and-multiple-linear-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Linear Regression and Multiple Linear Regression</h3>

<h3 id="simple-linear-regression">
<a class="anchor" href="#simple-linear-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Simple Linear Regression</h3>
<p>Simple Linear Regression is a method to help us understand the relationship between two variables:</p>
<ul>
  <li>The predictor/independent variable (X)</li>
  <li>The response/dependent variable (that we want to predict)(Y)</li>
</ul>

<p>The result of Linear Regression is a linear function that predicts the response (dependent) variable as a function of the predictor (independent) variable.</p>

<p>Y: Response Variable<br>
X: Predictor Varaible</p>

<p>Linear function:
𝑌ℎ𝑎𝑡 = 𝑎 + 𝑏𝑋</p>
<ul>
  <li>a refers to the intercept of the regression line, in other words: the value of Y when X is 0</li>
  <li>b refers to the slope of the regression line, in other words: the value with which Y changes when X increases by 1 unit</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load the module for linear regression
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
</code></pre></div></div>

<h6 id="how-can-highway-mpg-help-predict-the-price">
<a class="anchor" href="#how-can-highway-mpg-help-predict-the-price" aria-hidden="true"><span class="octicon octicon-link"></span></a>How can highway-mpg help predict the price?</h6>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create the linear regression object
</span><span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lm</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'highway-mpg'</span><span class="p">]]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>

<span class="c1"># fit the linear model using highway-mpg
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># output a prediction
</span><span class="n">Yhat</span> <span class="o">=</span> <span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([16236.50464347, 16236.50464347, 17058.23802179, 13771.3045085 ,
       20345.17153508])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># value of intercept a
</span><span class="n">lm</span><span class="p">.</span><span class="n">intercept_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>38423.305858157386
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># value of slope b
</span><span class="n">lm</span><span class="p">.</span><span class="n">coef_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([-821.73337832])
</code></pre></div></div>

<p>Final estimated linear model:<br>
price = 38423.31 - 821.73 * highway-mpg</p>

<h6 id="how-can-engine-size-help-predict-the-price">
<a class="anchor" href="#how-can-engine-size-help-predict-the-price" aria-hidden="true"><span class="octicon octicon-link"></span></a>How can engine size help predict the price?</h6>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'engine-size'</span><span class="p">]]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>

<span class="c1"># fit the linear model using highway-mpg
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># output a prediction
</span><span class="n">Yhat</span> <span class="o">=</span> <span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([13728.4631336 , 13728.4631336 , 17399.38347881, 10224.40280408,
       14729.62322775])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># value of intercept a
</span><span class="n">lm</span><span class="p">.</span><span class="n">intercept_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-7963.338906281049
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># value of slope b
</span><span class="n">lm</span><span class="p">.</span><span class="n">coef_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([166.86001569])
</code></pre></div></div>

<p>Final estimated linear model:<br>
Price = -7963.34 + 166.86 * Engine-size</p>

<h3 id="multiple-linear-regression">
<a class="anchor" href="#multiple-linear-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiple Linear Regression</h3>

<p>If we want to use more variables in our model to predict car price, we can use Multiple Linear Regression.<br>
This method is used to explain the relationship between one continuous response (dependent) variable and two or more predictor (independent) variables. Most of the real-world regression models involve multiple predictors.</p>

<p><em>𝑌ℎ𝑎𝑡 = 𝑎 + 𝑏1𝑋1 + 𝑏2𝑋2 + 𝑏3𝑋3 + 𝑏4𝑋4</em></p>

<p>From the previous section we know that other good predictors of price could be:</p>

<ul>
  <li>Horsepower</li>
  <li>Curb-weight</li>
  <li>Engine-size</li>
  <li>Highway-mpg</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># develop a model using these variables as the predictor variables
</span><span class="n">Z</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># fit the linear model using the above four variables
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># value of the intercept
</span><span class="n">lm</span><span class="p">.</span><span class="n">intercept_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-15806.624626329198
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># value of the coefficients (b1, b2, b3, b4)
</span><span class="n">lm</span><span class="p">.</span><span class="n">coef_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([53.49574423,  4.70770099, 81.53026382, 36.05748882])
</code></pre></div></div>

<p>Final estimated linear model:<br>
Price = -15678.74 + 52.65851272 * horsepower + 4.699 * curb-weight + 81.96 * engine-size + 33.58 * highway-mpg</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use two other predictor variables
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s">'normalized-losses'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># value of the intercept
</span><span class="n">lm</span><span class="p">.</span><span class="n">intercept_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>38201.31327245728
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># value of the coefficients (b1, b2)
</span><span class="n">lm</span><span class="p">.</span><span class="n">coef_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([   1.49789586, -820.45434016])
</code></pre></div></div>

<p>Final estimated linear model:<br>
Price = 38201.31 + 1.498 * normalized-losses - 820.45 * highway-mpg</p>

<h2 id="model-evaluation-using-visualization">
<a class="anchor" href="#model-evaluation-using-visualization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model Evaluation using Visualization</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import the visualization package: seaborn
</span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<h3 id="regression-plot-for-simple-linear-regression">
<a class="anchor" href="#regression-plot-for-simple-linear-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Regression Plot for Simple Linear Regression</h3>
<p>This plot will show a combination of a scattered data points (a scatter plot), as well as the fitted linear regression line going through the data. This will give us a reasonable estimate of the relationship between the two variables, the strength of the correlation, as well as the direction (positive or negative correlation).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># visualize highway-mpg as a potential predictor of price
</span><span class="n">width</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">height</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'highway-mpg'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0, 48163.464897503036)
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_176_1.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_176_1.png"> --></p>

<p>We can see from this plot that price is negatively correlated to highway-mpg, since the regression slope is negative. One thing to keep in mind when looking at a regression plot is to pay attention to how scattered the data points are around the regression line. This will give you a good indication of the variance of the data, and whether a linear model would be the best fit or not. If the data is too far off from the line, this linear model might not be the best model for this data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># visualize peak-rpm as a potential predictor of price
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'peak-rpm'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0, 47414.10667770421)
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_178_1.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_178_1.png"> --></p>

<p>Comparing the regression plot of “peak-rpm” and “highway-mpg” we see that the points for “highway-mpg” are much closer to the generated line and on the average decrease. The points for “peak-rpm” have more spread around the predicted line, and it is much harder to determine if the points are decreasing or increasing as the “highway-mpg” increases.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># find whether peak-rpm or highway-mpg is more strongly correlated with price
</span><span class="n">df</span><span class="p">[[</span><span class="s">'peak-rpm'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>peak-rpm</th>
      <th>highway-mpg</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>peak-rpm</th>
      <td>1.000000</td>
      <td>-0.058598</td>
      <td>-0.101616</td>
    </tr>
    <tr>
      <th>highway-mpg</th>
      <td>-0.058598</td>
      <td>1.000000</td>
      <td>-0.704692</td>
    </tr>
    <tr>
      <th>price</th>
      <td>-0.101616</td>
      <td>-0.704692</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>As we can see, highway-mpg is more strongly correlated with price as compared to peak-rpm.</p>

<h5 id="residual-plot-to-visualize-variance-of-data">
<a class="anchor" href="#residual-plot-to-visualize-variance-of-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Residual Plot to visualize variance of data</h5>

<p>The difference between the observed value (y) and the predicted value (Yhat) is called the residual (e). When we look at a regression plot, the residual is the distance from the data point to the fitted regression line.</p>

<p>A residual plot is a graph that shows the residuals on the vertical y-axis and the independent variable on the horizontal x-axis.</p>

<p>We look at the spread of the residuals:</p>
<ul>
  <li>If the points in a residual plot are randomly spread out around the x-axis, then a linear model is appropriate for the data.</li>
  <li>Randomly spread out residuals means that the variance is constant, and thus the linear model is a good fit for this data.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a residal plot
</span><span class="n">width</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">height</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">residplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'highway-mpg'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_183_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_183_0.png"> --></p>

<p>We can see from this residual plot that the residuals are not randomly spread around the x-axis, which leads us to believe that maybe a non-linear model is more appropriate for this data.</p>

<h3 id="distribution-plot-for-multiple-linear-regression">
<a class="anchor" href="#distribution-plot-for-multiple-linear-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Distribution Plot for Multiple Linear Regression</h3>
<p>You cannot visualize Multiple Linear Regression with a regression or residual plot.<br>
One way to look at the fit of the model is by looking at the distribution plot. We can look at the distribution of the fitted values that result from the model and compare it to the distribution of the actual values.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># develop a model using these variables as the predictor variables
</span><span class="n">Z</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># fit the linear model using the above four variables
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># make a prediction 
</span><span class="n">Y_hat</span> <span class="o">=</span> <span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">hist</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Actual Value'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">Yhat</span><span class="p">,</span> <span class="n">hist</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Fitted Values'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Actual vs Fitted Values for Price'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Price (in dollars)'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Proportion of Cars'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_189_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_189_0.png"> --></p>

<p>We can see that the fitted values are reasonably close to the actual values, since the two distributions overlap a bit. However, there is definitely some room for improvement.</p>

<h2 id="polynomial-regression-and-pipelines">
<a class="anchor" href="#polynomial-regression-and-pipelines" aria-hidden="true"><span class="octicon octicon-link"></span></a>Polynomial Regression and Pipelines</h2>
<p>Polynomial regression is a particular case of the general linear regression model or multiple linear regression models.<br>
We get non-linear relationships by squaring or setting higher-order terms of the predictor variables.</p>

<p>There are different orders of polynomial regression:</p>
<ul>
  <li>Quadratic - 2nd order<br>
𝑌ℎ𝑎𝑡=𝑎+𝑏1𝑋2+𝑏2𝑋2</li>
  <li>Cubic - 3rd order<br>
𝑌ℎ𝑎𝑡=𝑎+𝑏1𝑋2+𝑏2𝑋2+𝑏3𝑋3</li>
  <li>Higher order:<br>
𝑌=𝑎+𝑏1𝑋2+𝑏2𝑋2+𝑏3𝑋3….</li>
</ul>

<p>We saw earlier that a linear model did not provide the best fit while using highway-mpg as the predictor variable. Let’s see if we can try fitting a polynomial model to the data instead.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot the data
</span><span class="k">def</span> <span class="nf">PlotPolly</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">independent_variable</span><span class="p">,</span> <span class="n">dependent_variable</span><span class="p">,</span> <span class="n">Name</span><span class="p">):</span>
    <span class="n">x_new</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">y_new</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">independent_variable</span><span class="p">,</span> <span class="n">dependent_variable</span><span class="p">,</span> <span class="s">'.'</span><span class="p">,</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">y_new</span><span class="p">,</span> <span class="s">'-'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Polynomial Fit with Matplotlib for Price ~ Length'</span><span class="p">)</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_facecolor</span><span class="p">((</span><span class="mf">0.898</span><span class="p">,</span> <span class="mf">0.898</span><span class="p">,</span> <span class="mf">0.898</span><span class="p">))</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Name</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Price of Cars'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get the variables
</span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'highway-mpg'</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># fit the polynomial using the polyfit function
# we use a polynomial of the 3rd order
</span><span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># use the poly1d function to display the polynomial function
</span><span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        3         2
-1.557 x + 204.8 x - 8965 x + 1.379e+05
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot the function
</span><span class="n">PlotPolly</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_195_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_195_0.png"> --></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([-1.55663829e+00,  2.04754306e+02, -8.96543312e+03,  1.37923594e+05])
</code></pre></div></div>

<p>We can already see from plotting that this polynomial model performs better than the linear model. This is because the generated polynomial function “hits” more of the data points.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create an 11 order polynomial model with the same variables
</span><span class="n">f1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">p1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            11             10             9           8         7
-1.243e-08 x  + 4.722e-06 x  - 0.0008028 x + 0.08056 x - 5.297 x
          6        5             4             3             2
 + 239.5 x - 7588 x + 1.684e+05 x - 2.565e+06 x + 2.551e+07 x - 1.491e+08 x + 3.879e+08
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PlotPolly</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_199_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_199_0.png"> --></p>

<p>We see that by using very high order polynomials, overfitting is observed.</p>

<h3 id="multivariate-polynomial-function">
<a class="anchor" href="#multivariate-polynomial-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multivariate Polynomial Function</h3>
<p>The analytical expression for Multivariate Polynomial function gets complicated. For example, the expression for a second-order (degree=2)polynomial with two variables is given by:</p>

<p>𝑌ℎ𝑎𝑡=𝑎+𝑏1𝑋1+𝑏2𝑋2+𝑏3𝑋1𝑋2+𝑏4𝑋21+𝑏5𝑋22</p>

<p>We will now perform a polynomial transform on multiple features.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import the module
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a PolynomialFeatures object of degree 2
</span><span class="n">pr</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pr</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,
                   order='C')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Z_pr</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Z</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(201, 4)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Z_pr</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(201, 15)
</code></pre></div></div>

<h3 id="pipeline">
<a class="anchor" href="#pipeline" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pipeline</h3>
<p>Data Pipelines simplify the steps of processing the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create the pipeline
# create a list of tuples inlcuding the name of the model/estimator and its corresponding constructor
</span><span class="n">Input</span> <span class="o">=</span> <span class="p">[(</span><span class="s">'scale'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span> <span class="p">(</span><span class="s">'polynomial'</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">include_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)),</span> <span class="p">(</span><span class="s">'model'</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># input the list as an argument to the pipeline constructor
</span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">Input</span><span class="p">)</span>
<span class="n">pipe</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Pipeline(memory=None,
         steps=[('scale',
                 StandardScaler(copy=True, with_mean=True, with_std=True)),
                ('polynomial',
                 PolynomialFeatures(degree=2, include_bias=False,
                                    interaction_only=False, order='C')),
                ('model',
                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
                                  normalize=False))],
         verbose=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># we can normalize the data, perform a transform and fit the model simultaneously
</span><span class="n">pipe</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Pipeline(memory=None,
         steps=[('scale',
                 StandardScaler(copy=True, with_mean=True, with_std=True)),
                ('polynomial',
                 PolynomialFeatures(degree=2, include_bias=False,
                                    interaction_only=False, order='C')),
                ('model',
                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
                                  normalize=False))],
         verbose=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># we can normalize the data, perform a transform and produced a prediction simultaneously
</span><span class="n">ypipe</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="n">ypipe</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([13102.74784201, 13102.74784201, 18225.54572197, 10390.29636555,
       16136.29619164, 13880.09787302, 15041.58694037, 15457.93465485,
       17974.49032347, 10510.56542385])
</code></pre></div></div>

<h2 id="measures-for-in-sample-evaluation">
<a class="anchor" href="#measures-for-in-sample-evaluation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Measures for In-Sample Evaluation</h2>
<p>When evaluating our models, not only do we want to visualize the results, but we also want a quantitative measure to determine how accurate the model is.</p>

<p>Two very important measures that are often used in Statistics to determine the accuracy of a model are:</p>
<ul>
  <li>R^2 / R-squared</li>
  <li>Mean Squared Error (MSE)</li>
</ul>

<p><strong>R-squared:</strong> R squared, also known as the coefficient of determination, is a measure to indicate how close the data is to the fitted regression line. The value of the R-squared is the percentage of variation of the response variable (y) that is explained by a linear model.</p>

<p><strong>Mean Squared Error (MSE):</strong> The Mean Squared Error measures the average of the squares of errors, that is, the difference between actual value (y) and the estimated value (ŷ).</p>

<h3 id="model-1-simple-linear-regression">
<a class="anchor" href="#model-1-simple-linear-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model 1: Simple Linear Regression</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'highway-mpg'</span><span class="p">]]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>
<span class="c1"># highway_mpg_fit
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="c1"># calculate the R^2
</span><span class="k">print</span><span class="p">(</span><span class="s">'The R-square is:'</span><span class="p">,</span> <span class="n">lm</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The R-square is: 0.4965911884339175
</code></pre></div></div>

<p>We can say that ~ 49.659% of the variation of the price is explained by this simple linear model “highway_mpg_fit”.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># predict the output
</span><span class="n">Yhat</span> <span class="o">=</span> <span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The output of the first four predicted values is'</span><span class="p">,</span> <span class="n">Yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The output of the first four predicted values is [16236.50464347 16236.50464347 17058.23802179 13771.3045085 ]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import the module
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="c1"># calculate the MSE
</span><span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">Yhat</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The mean square error of price and predicted value is: '</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The mean square error of price and predicted value is:  31635042.944639895
</code></pre></div></div>

<h3 id="model-2-multiple-linear-regression">
<a class="anchor" href="#model-2-multiple-linear-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model 2: Multiple Linear Regression</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># fit the model
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="c1"># find the R^2
</span><span class="k">print</span><span class="p">(</span><span class="s">'The R-square value is: '</span><span class="p">,</span> <span class="n">lm</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The R-square value is:  0.8093562806577457
</code></pre></div></div>

<p>We can say that ~ 80.93 % of the variation of price is explained by this multiple linear regression “multi_fit”.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># produce a prediction
</span><span class="n">Y_predict_multifit</span> <span class="o">=</span> <span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte MSE
</span><span class="k">print</span><span class="p">(</span><span class="s">'The mean square error of price and predicted value using multifit is: '</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">Y_predict_multifit</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The mean square error of price and predicted value using multifit is:  11980366.87072649
</code></pre></div></div>

<h4 id="model-3-polynomial-fit">
<a class="anchor" href="#model-3-polynomial-fit" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model 3: Polynomial Fit</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import the module
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calculate R^2
</span><span class="n">r_squared</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The R-square value is: '</span><span class="p">,</span> <span class="n">r_squared</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The R-square value is:  0.674194666390652
</code></pre></div></div>

<p>We can say that ~ 67.419 % of the variation of price is explained by this polynomial fit.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calculate MSE
</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20474146.426361218
</code></pre></div></div>

<h2 id="prediction-and-decision-making">
<a class="anchor" href="#prediction-and-decision-making" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prediction and Decision Making</h2>
<h4 id="prediction">
<a class="anchor" href="#prediction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prediction</h4>
<p>We trained the model using fit. Now we will use the method ‘predict’ to produce a prediction.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a new input
</span><span class="n">new_input</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># fit the model
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">lm</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># produce a prediction
</span><span class="n">yhat</span> <span class="o">=</span> <span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_input</span><span class="p">)</span>
<span class="n">yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([37601.57247984, 36779.83910151, 35958.10572319, 35136.37234487,
       34314.63896655])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot the data
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new_input</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_234_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_234_0.png"> --></p>

<h3 id="decision-making-determing-a-good-model-fit">
<a class="anchor" href="#decision-making-determing-a-good-model-fit" aria-hidden="true"><span class="octicon octicon-link"></span></a>Decision Making: Determing a Good Model Fit</h3>
<p>Now that we have visualized the different models, and generated the R-squared and MSE values for the fits, how do we determine a good model fit?</p>

<p>What is a good R-squared value?
When comparing models, the model with the higher R-squared value is a better fit for the data.</p>

<p>What is a good MSE?
When comparing models, the model with the smallest MSE value is a better fit for the data.</p>

<h4 id="lets-take-a-look-at-the-values-for-the-different-models">
<a class="anchor" href="#lets-take-a-look-at-the-values-for-the-different-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Let’s take a look at the values for the different models.</h4>

<p>Simple Linear Regression: Using Highway-mpg as a Predictor Variable of Price.</p>
<ul>
  <li>R-squared: 0.49659118843391759</li>
  <li>MSE: 3.16 x10^7</li>
</ul>

<p>Multiple Linear Regression: Using Horsepower, Curb-weight, Engine-size, and Highway-mpg as Predictor Variables of Price.</p>
<ul>
  <li>R-squared: 0.80896354913783497</li>
  <li>MSE: 1.2 x10^7</li>
</ul>

<p>Polynomial Fit: Using Highway-mpg as a Predictor Variable of Price.</p>
<ul>
  <li>R-squared: 0.6741946663906514</li>
  <li>MSE: 2.05 x 10^7</li>
</ul>

<h4 id="simple-linear-regression-model-slr-vs-multiple-linear-regression-model-mlr">
<a class="anchor" href="#simple-linear-regression-model-slr-vs-multiple-linear-regression-model-mlr" aria-hidden="true"><span class="octicon octicon-link"></span></a>Simple Linear Regression model (SLR) vs Multiple Linear Regression model (MLR)</h4>
<p>Usually, the more variables you have, the better your model is at predicting, but this is not always true. Sometimes you may not have enough data, you may run into numerical problems, or many of the variables may not be useful and or even act as noise. As a result, you should always check the MSE and R^2.<br>
So to be able to compare the results of the MLR vs SLR models, we look at a combination of both the R-squared and MSE to make the best conclusion about the fit of the model.</p>

<ul>
  <li>
<strong>MSE:</strong> The MSE of SLR is 3.16x10^7 while MLR has an MSE of 1.2 x10^7. The MSE of MLR is much smaller.</li>
  <li>
<strong>R-squared:</strong> In this case, we can also see that there is a big difference between the R-squared of the SLR and the R-squared of the MLR. The R-squared for the SLR (0.497) is very small compared to the R-squared for the MLR (0.809).<br>
This R-squared in combination with the MSE show that MLR seems like the better model fit in this case, compared to SLR.</li>
</ul>

<h4 id="simple-linear-model-slr-vs-polynomial-fit">
<a class="anchor" href="#simple-linear-model-slr-vs-polynomial-fit" aria-hidden="true"><span class="octicon octicon-link"></span></a>Simple Linear Model (SLR) vs Polynomial Fit</h4>
<ul>
  <li>
<strong>MSE:</strong> We can see that Polynomial Fit brought down the MSE, since this MSE is smaller than the one from the SLR.</li>
  <li>
<strong>R-squared:</strong> The R-squared for the Polyfit is larger than the R-squared for the SLR, so the Polynomial Fit also brought up the R-squared quite a bit.<br>
Since the Polynomial Fit resulted in a lower MSE and a higher R-squared, we can conclude that this was a better fit model than the simple linear regression for predicting Price with Highway-mpg as a predictor variable.</li>
</ul>

<h4 id="multiple-linear-regression-mlr-vs-polynomial-fit">
<a class="anchor" href="#multiple-linear-regression-mlr-vs-polynomial-fit" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiple Linear Regression (MLR) vs Polynomial Fit</h4>
<ul>
  <li>
<strong>MSE:</strong> The MSE for the MLR is smaller than the MSE for the Polynomial Fit.</li>
  <li>
<strong>R-squared:</strong> The R-squared for the MLR is also much larger than for the Polynomial Fit.</li>
</ul>

<h4 id="conclusion">
<a class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion:</h4>
<p>Comparing these three models, we conclude that <strong>the MLR model is the best model</strong> to be able to predict price from our dataset. This result makes sense, since we have 27 variables in total, and we know that more than one of those variables are potential predictors of the final car price.</p>

<h2 id="model-evaluation-and-refinement">
<a class="anchor" href="#model-evaluation-and-refinement" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model Evaluation and Refinement</h2>
<p>We have built models and made predictions of vehicle prices. Now we will determine how accurate these predictions are.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path</span> <span class="o">=</span> <span class="s">'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/module_5_auto.csv'</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># first let's only use numeric data
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">_get_numeric_data</span><span class="p">()</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>Unnamed: 0.1</th>
      <th>symboling</th>
      <th>normalized-losses</th>
      <th>wheel-base</th>
      <th>length</th>
      <th>width</th>
      <th>height</th>
      <th>curb-weight</th>
      <th>engine-size</th>
      <th>...</th>
      <th>stroke</th>
      <th>compression-ratio</th>
      <th>horsepower</th>
      <th>peak-rpm</th>
      <th>city-mpg</th>
      <th>highway-mpg</th>
      <th>price</th>
      <th>city-L/100km</th>
      <th>diesel</th>
      <th>gas</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>122</td>
      <td>88.6</td>
      <td>0.811148</td>
      <td>0.890278</td>
      <td>48.8</td>
      <td>2548</td>
      <td>130</td>
      <td>...</td>
      <td>2.68</td>
      <td>9.0</td>
      <td>111.0</td>
      <td>5000.0</td>
      <td>21</td>
      <td>27</td>
      <td>13495.0</td>
      <td>11.190476</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>122</td>
      <td>88.6</td>
      <td>0.811148</td>
      <td>0.890278</td>
      <td>48.8</td>
      <td>2548</td>
      <td>130</td>
      <td>...</td>
      <td>2.68</td>
      <td>9.0</td>
      <td>111.0</td>
      <td>5000.0</td>
      <td>21</td>
      <td>27</td>
      <td>16500.0</td>
      <td>11.190476</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>122</td>
      <td>94.5</td>
      <td>0.822681</td>
      <td>0.909722</td>
      <td>52.4</td>
      <td>2823</td>
      <td>152</td>
      <td>...</td>
      <td>3.47</td>
      <td>9.0</td>
      <td>154.0</td>
      <td>5000.0</td>
      <td>19</td>
      <td>26</td>
      <td>16500.0</td>
      <td>12.368421</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>164</td>
      <td>99.8</td>
      <td>0.848630</td>
      <td>0.919444</td>
      <td>54.3</td>
      <td>2337</td>
      <td>109</td>
      <td>...</td>
      <td>3.40</td>
      <td>10.0</td>
      <td>102.0</td>
      <td>5500.0</td>
      <td>24</td>
      <td>30</td>
      <td>13950.0</td>
      <td>9.791667</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>164</td>
      <td>99.4</td>
      <td>0.848630</td>
      <td>0.922222</td>
      <td>54.3</td>
      <td>2824</td>
      <td>136</td>
      <td>...</td>
      <td>3.40</td>
      <td>8.0</td>
      <td>115.0</td>
      <td>5500.0</td>
      <td>18</td>
      <td>22</td>
      <td>17450.0</td>
      <td>13.055556</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import the modules
</span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">IPython.html</span> <span class="kn">import</span> <span class="n">widgets</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>C:\Users\prana\Anaconda3\lib\site-packages\IPython\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.
  "`IPython.html.widgets` has moved to `ipywidgets`.", ShimWarning)
</code></pre></div></div>

<h4 id="functions-for-plotting">
<a class="anchor" href="#functions-for-plotting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Functions for Plotting</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">DistributionPlot</span><span class="p">(</span><span class="n">RedFunction</span><span class="p">,</span> <span class="n">BlueFunction</span><span class="p">,</span> <span class="n">RedName</span><span class="p">,</span> <span class="n">BlueName</span><span class="p">,</span> <span class="n">Title</span><span class="p">):</span>
  <span class="n">width</span> <span class="o">=</span> <span class="mi">12</span>
  <span class="n">height</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>

  <span class="n">ax1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">RedFunction</span><span class="p">,</span> <span class="n">hist</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">RedName</span><span class="p">)</span>
  <span class="n">ax2</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">BlueFunction</span><span class="p">,</span> <span class="n">hist</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">BlueName</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>

  <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">Title</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Price (in dollars)'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Proportion of Cars'</span><span class="p">)</span>

  <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">PollyPlot</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">xtest</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span><span class="n">poly_transform</span><span class="p">):</span>
  <span class="c1">#training data 
</span>  <span class="c1">#testing data 
</span>  <span class="c1"># lr:linear regression object     #poly_transform:polynomial transformation object 
</span>  <span class="n">width</span> <span class="o">=</span> <span class="mi">12</span>
  <span class="n">height</span> <span class="o">=</span> <span class="mi">10</span>    
  <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
 
  <span class="n">xmax</span><span class="o">=</span><span class="nb">max</span><span class="p">([</span><span class="n">xtrain</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nb">max</span><span class="p">(),</span> <span class="n">xtest</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nb">max</span><span class="p">()])</span>
  <span class="n">xmin</span><span class="o">=</span><span class="nb">min</span><span class="p">([</span><span class="n">xtrain</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">xtest</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nb">min</span><span class="p">()])</span>
  <span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

  <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s">'ro'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Training Data'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="s">'go'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Test Data'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">poly_transform</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span> <span class="n">label</span><span class="o">=</span><span class="s">'Predicted Function'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">60000</span><span class="p">])</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Price'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="training-and-testing">
<a class="anchor" href="#training-and-testing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training and Testing</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># place target data 'price' in a seaparate dataframe y
</span><span class="n">y_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># drop price data in x_data
</span><span class="n">x_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'price'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># randomly split the data into training and testing data using the function train_test_split
</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># test_size setes the proportion of data that is split. The testing set is set to 10% of the total dataset.
# use the same random_state value throughout your code
</span>
<span class="k">print</span><span class="p">(</span><span class="s">'number of test samples: '</span><span class="p">,</span> <span class="n">x_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'number of training samples: '</span><span class="p">,</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>number of test samples:  21
number of training samples:  180
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import LinearRegression module
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># create Linear Regression object
</span><span class="n">lre</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># fit the model using the feature 'horsepower'
</span><span class="n">lre</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calculate R^2 on the test data
</span><span class="n">lre</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.3635875575078824
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcuate R^2 on the training data
</span><span class="n">lre</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.6619724197515103
</code></pre></div></div>

<p>We can see that the R^2 is much smaller using the test data.</p>

<h3 id="cross-validation-score">
<a class="anchor" href="#cross-validation-score" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cross-Validation Score</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import the module
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># input the object(lre), the feature(horsepower), the target data(y_data), number of folds(cv)
</span><span class="n">Rcross</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lre</span><span class="p">,</span> <span class="n">x_data</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">Rcross</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0.7746232 , 0.51716687, 0.74785353, 0.04839605])
</code></pre></div></div>

<p>The default scoring is R^2. Each element in the array has the average R^2 value in the fold.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calculate the average and standard deviation of our estimate
</span><span class="k">print</span><span class="p">(</span><span class="s">'The mean of the folds is'</span><span class="p">,</span> <span class="n">Rcross</span><span class="p">.</span><span class="n">mean</span><span class="p">(),</span> <span class="s">'and the standard deviation is'</span><span class="p">,</span> <span class="n">Rcross</span><span class="p">.</span><span class="n">std</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The mean of the folds is 0.522009915042119 and the standard deviation is 0.2911839444756029
</code></pre></div></div>

<p>We can use negative squared error as a score by setting the parameter ‘scoring’ metric to ‘neg_mean_squared_error’.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lre</span><span class="p">,</span> <span class="n">x_data</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([20254142.84026704, 43745493.2650517 , 12539630.34014931,
       17561927.72247591])
</code></pre></div></div>

<p>Use the function ‘cross_val_predict’ to predict the output. The function splits up the data into the specified number of folds, using one fold to get a prediction while the rest of the folds are used as test data. First import the function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="n">yhat</span><span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">lre</span><span class="p">,</span> <span class="n">x_data</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([14141.63807508, 14141.63807508, 20814.29423473, 12745.03562306,
       14762.35027598])
</code></pre></div></div>

<h3 id="overfitting-underfitting-and-model-selection">
<a class="anchor" href="#overfitting-underfitting-and-model-selection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overfitting, Underfitting and Model Selection</h3>
<p>It turns out that the test data sometimes referred to as the out of sample data is a much better measure of how well your model performs in the real world. One reason for this is overfitting; let’s go over some examples. It turns out these differences are more apparent in Multiple Linear Regression and Polynomial Regression so we will explore overfitting in that context.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create MLR objects and train the model
</span><span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># prediction using training data
</span><span class="n">y_hat_train</span> <span class="o">=</span> <span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]])</span>
<span class="n">y_hat_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([ 7426.6731551 , 28323.75090803, 14213.38819709,  4052.34146983,
       34500.19124244])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># prediction using test data
</span><span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]])</span>
<span class="n">y_hat_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([11349.35089149,  5884.11059106, 11208.6928275 ,  6641.07786278,
       15565.79920282])
</code></pre></div></div>

<p>Lets perform some model evaluation using our training and testing data separately.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import seaborn and matplotlib libraries
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># examine the distribution of the predicted values of the training data
</span><span class="n">Title</span> <span class="o">=</span> <span class="s">'Distribution Plot of Predicted Value using Training Data vs Training Data distribution'</span>
<span class="n">DistributionPlot</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_hat_train</span><span class="p">,</span> <span class="s">'Actual Values (Train)'</span><span class="p">,</span> <span class="s">'Predicted Values (Train)'</span><span class="p">,</span> <span class="n">Title</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_268_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_268_0.png"> --></p>

<p>Figure 1: Plot of predicted values using the training data compared to the training data.</p>

<p>So far the model seems to be doing well in learning from the training dataset. But what happens when the model encounters new data from the testing dataset?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># examine the distribution of the predicted values of the test data
</span><span class="n">Title</span> <span class="o">=</span> <span class="s">'Distribution Plot of Predicted Value using Test Data vs Data Distribution of Test Data'</span>
<span class="n">DistributionPlot</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_hat_test</span><span class="p">,</span> <span class="s">'Actual Values (Test)'</span><span class="p">,</span> <span class="s">'Predicted Values (Test)'</span><span class="p">,</span> <span class="n">Title</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_271_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_271_0.png"> --></p>

<p>Figure 2: Plot of predicted value using the test data compared to the test data.</p>

<p>When the model generates new values from the test data, we see the distribution of the predicted values is much different from the actual target values.<br>
Comparing Figure 1 and Figure 2, it is evident the distribution of the training data in Figure 1 is much better at fitting the data. This difference in Figure 2 is apparent where the ranges are from 5000 to 15000. This is where the distribution shape is exceptionally different.</p>

<p>Let’s see if polynomial regression also exhibits a drop in the prediction accuracy when analysing the test dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
</code></pre></div></div>

<h3 id="overfitting">
<a class="anchor" href="#overfitting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overfitting</h3>
<p>Overfitting occurs when the model fits the noise, not the underlying process. Therefore when testing your model using the test-set, your model does not perform as well as it is modelling noise, not the underlying process that generated the relationship.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use 45% of the data for testing and the rest for training
</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.45</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># perform a degree 5 polynomial transformation on the feature 'horsepower'
</span><span class="n">pr</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">x_train_pr</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]])</span>
<span class="n">x_test_pr</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]])</span>
<span class="n">pr</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PolynomialFeatures(degree=5, include_bias=True, interaction_only=False,
                   order='C')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a linear regression model 
</span><span class="n">poly</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># train the model
</span><span class="n">poly</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_pr</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># see the output of the model using predict
</span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">poly</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_pr</span><span class="p">)</span>
<span class="n">yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([14141.63807508, 14141.63807508, 20814.29423473, 12745.03562306,
       14762.35027598])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># take the first five predicted values and compare it to the actual targets
</span><span class="k">print</span><span class="p">(</span><span class="s">'Predicted values:'</span><span class="p">,</span> <span class="n">yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'True values'</span><span class="p">,</span> <span class="n">y_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Predicted values: [14141.63807508 14141.63807508 20814.29423473 12745.03562306]
True values [ 6295. 10698. 13860. 13499.]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># display the plot
</span><span class="n">PollyPlot</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">x_test</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">poly</span><span class="p">,</span> <span class="n">pr</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_282_0.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_282_0.png"> --></p>

<p>Figure 3: A polynomial regression model; red dots represent training data, green dots represent test data, and the blue line represents the model prediction.</p>

<p>We see that the estimated function appears to track the data but around 200 horsepower, the function begins to diverge from the data points.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># R^2 of training data
</span><span class="n">poly</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train_pr</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.5567716902635091
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># R^2 of test data
</span><span class="n">poly</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test_pr</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-29.87141885918752
</code></pre></div></div>

<p>We see the R^2 for the training data is 0.5567 while the R^2 on the test data was -29.87. The lower the R^2, the worse the model, a Negative R^2 is a sign of overfitting.</p>

<p>Let’s see how the R^2 changes on the test data for different order polynomials and plot the results.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Rsqu_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">order</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">order</span><span class="p">:</span>
  <span class="n">pr</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
  <span class="n">x_train_pr</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]])</span>
  <span class="n">x_test_pr</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]])</span>    
  <span class="n">lr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_pr</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
  <span class="n">Rsqu_test</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test_pr</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">Rsqu_test</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'order'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'R^2'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'R^2 Using Test Data'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="s">'Maximum R^2 '</span><span class="p">)</span>    
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(3, 0.75, 'Maximum R^2 ')
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_289_1.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_289_1.png"> --></p>

<p>We see the R^2 gradually increases until an order three polynomial is used. Then the R^2 dramatically decreases at four.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">pr</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
    <span class="n">x_train_pr</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]])</span>
    <span class="n">x_test_pr</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]])</span>
    <span class="n">poly</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">poly</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_pr</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">PollyPlot</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">x_test</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span> <span class="n">poly</span><span class="p">,</span> <span class="n">pr</span><span class="p">)</span>
</code></pre></div></div>

<p>The following interface allows you to experiment with different polynomial orders and different amounts of data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">interact</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">test_data</span><span class="o">=</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>interactive(children=(IntSlider(value=3, description='order', max=6), FloatSlider(value=0.45, description='tes…





&lt;function __main__.f(order, test_data)&gt;
</code></pre></div></div>

<h3 id="ridge-regression">
<a class="anchor" href="#ridge-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Ridge Regression</h3>
<p>Review Ridge Regression, see how the parameter Alpha changes the model. Our test data will be used as validation data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># perform a degree 2 polynomial transformation on our data
</span><span class="n">pr</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x_train_pr</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">,</span> <span class="s">'normalized-losses'</span><span class="p">,</span> <span class="s">'symboling'</span><span class="p">]])</span>
<span class="n">x_test_pr</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">,</span><span class="s">'normalized-losses'</span><span class="p">,</span><span class="s">'symboling'</span><span class="p">]])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import Ridge from the module
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a Ridge Regression object, setting the regularization parameter to 0.1
</span><span class="n">RidgeModel</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># fit the model
</span><span class="n">RidgeModel</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_pr</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>C:\Users\prana\Anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.02972e-16): result may not be accurate.
  overwrite_a=True).T





Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=None, solver='auto', tol=0.001)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get the prediction
</span><span class="n">yhat</span> <span class="o">=</span> <span class="n">RidgeModel</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_pr</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Compare the first 5 predicted samples to our test set
</span><span class="k">print</span><span class="p">(</span><span class="s">'predicted:'</span><span class="p">,</span> <span class="n">yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'test set:'</span><span class="p">,</span> <span class="n">y_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>predicted: [ 6567.83081933  9597.97151399 20836.22326843 19347.69543463]
test set: [ 6295. 10698. 13860. 13499.]
</code></pre></div></div>

<p>Select the value of Alpha that minimizes the test error. For e.g., we can use a loop.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Rsqu_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Rsqu_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">dummy1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">ALPHA</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1000</span><span class="p">))</span>
<span class="k">for</span> <span class="n">alfa</span> <span class="ow">in</span> <span class="n">ALPHA</span><span class="p">:</span>
    <span class="n">RigeModel</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alfa</span><span class="p">)</span> 
    <span class="n">RigeModel</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_pr</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">Rsqu_test</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">RigeModel</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test_pr</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
    <span class="n">Rsqu_train</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">RigeModel</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train_pr</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot the value of R^2 for different Alphas
</span><span class="n">width</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">height</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ALPHA</span><span class="p">,</span><span class="n">Rsqu_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'validation data  '</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ALPHA</span><span class="p">,</span><span class="n">Rsqu_train</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'training Data '</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'R^2'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x1d19ca7f780&gt;
</code></pre></div></div>

<p><img src="/ai/images/dataAnalysisWithPython/output_303_1.png%22" alt="">
<!-- <img src = "/assets/img/dataAnalysisWithPython/output_303_1.png"> --></p>

<p>Figure 6: The blue line represents the R^2 of the test data, and the red line represents the R^2 of the training data. The x-axis represents the different values of Alpha.</p>

<h3 id="grid-search">
<a class="anchor" href="#grid-search" aria-hidden="true"><span class="octicon octicon-link"></span></a>Grid Search</h3>
<p>The term Alpha is a hyperparameter; sklearn has the class GridSearchCV to make the process of finding the best hyperparameter simpler.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import GridSearchCV from the module model_selection
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a dictionary of parameter values
</span><span class="n">parameters1</span> <span class="o">=</span> <span class="p">[{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">]}]</span>
<span class="n">parameters1</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{'alpha': [0.001, 0.1, 1, 10, 100, 1000, 10000, 100000]}]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a Ridge regions object
</span><span class="n">RR</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span>
<span class="n">RR</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=None, solver='auto', tol=0.001)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a ridge grid seacrch object
</span><span class="n">Grid1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">RR</span><span class="p">,</span> <span class="n">parameters1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Fit the model
</span><span class="n">Grid1</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_data</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]],</span> <span class="n">y_data</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GridSearchCV(cv=4, error_score=nan,
             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,
                             max_iter=None, normalize=False, random_state=None,
                             solver='auto', tol=0.001),
             iid='deprecated', n_jobs=None,
             param_grid=[{'alpha': [0.001, 0.1, 1, 10, 100, 1000, 10000,
                                    100000]}],
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
             scoring=None, verbose=0)
</code></pre></div></div>

<p>The object finds the best parameter values on the validation data. We can obtain the estimator with the best parameters and assign it to the variable BestRR.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BestRR</span> <span class="o">=</span> <span class="n">Grid1</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">BestRR</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ridge(alpha=10000, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=None, solver='auto', tol=0.001)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test our model on the test data
</span><span class="n">BestRR</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]],</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.8411649831036149
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Perform a grid search for the alpha parameter and the normalization parameter, then find the best values of the parameters 
</span><span class="n">parameters2</span><span class="o">=</span> <span class="p">[{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span><span class="mi">10000</span><span class="p">,</span><span class="mi">100000</span><span class="p">,</span><span class="mi">100000</span><span class="p">],</span><span class="s">'normalize'</span><span class="p">:[</span><span class="bp">True</span><span class="p">,</span><span class="bp">False</span><span class="p">]}</span> <span class="p">]</span>
<span class="n">Grid2</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">Ridge</span><span class="p">(),</span> <span class="n">parameters2</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">Grid2</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_data</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]],</span><span class="n">y_data</span><span class="p">)</span>
<span class="n">Grid2</span><span class="p">.</span><span class="n">best_estimator_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None, normalize=True,
      random_state=None, solver='auto', tol=0.001)
</code></pre></div></div>


  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="pshirole/ai"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/ai/visualization/analysis/machine%20learning/2019/09/05/Data-Analyis-With-Python.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ai/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/ai/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/ai/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Data Science Profile</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/pshirole" title="pshirole"><svg class="svg-icon grey"><use xlink:href="/ai/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/pshirole" title="pshirole"><svg class="svg-icon grey"><use xlink:href="/ai/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
